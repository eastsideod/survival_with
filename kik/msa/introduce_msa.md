좋아요! 각 PDF를 바탕으로 MSA(Microservices Architecture)의 기초부터 심화 개념까지 학습할 수 있는 Markdown 파일을 주제별로 정리해드릴게요. 한국어로 작성하며, 예시 코드도 함께 포함하겠습니다.

각 주제는 다음과 같이 정리될 예정입니다:

- MSA 개요 및 기본 개념
- 서비스 설계 및 도메인 모델링
- 데이터 및 트랜잭션 처리
- 서비스 간 통신 및 안정성 패턴
- 테스트 및 모니터링
- 배포 전략 및 CI/CD 파이프라인
- 실습 예제와 코드 중심 학습 (ASP.NET Core, .NET Core Nancy 등)

준비가 완료되면 각 주제별 Markdown 파일로 나눠서 제공드릴게요.

# 마이크로서비스 개요

## 마이크로서비스란?

**마이크로서비스**(Microservice)는 하나의 응용 프로그램을 작고 독립적인 서비스들로 분해하는 아키텍처 스타일입니다. 각 서비스는 **단일 기능**에 집중하여 자기 완결적인 기능을 제공하며, 다른 서비스와 느슨하게 결합됩니다. 일반적으로 마이크로서비스는 다음과 같은 특징을 가집니다

- **단일 책임**: 하나의 마이크로서비스는 하나의 **기능 또는 업무 능력**만을 담당합니다. 예를 들어 결제 처리, 사용자 관리 등 각각 별도의 서비스로 구성됩니다 . 이는 **단일 책임 원칙(SRP)** 을 서비스 수준에서 적용한 것으로, 변경이 필요한 요구사항이 있을 때 해당 서비스만 수정하면 됩니다.
- **독립적 배포 가능**: 마이크로서비스는 각자 **별도의 프로세스**로 동작하며, 서비스 단위로 **개별적으로 배포**할 수 있습니다. 이 덕분에 한 서비스를 수정하여 배포하더라도 다른 서비스에는 영향을 주지 않을 수 있습니다. 실제로 Sam Newman은 “서비스를 변경하여 다른 부분은 손대지 않고 단독으로 배포할 수 있는가?”를 마이크로서비스 판단 기준으로 제시합니다.
- **자체 데이터 저장소 보유**: 각 서비스는 자신의 데이터베이스 또는 저장소를 관리하며, 다른 서비스와 **데이터 스키마를 공유하지 않습니다**. 이로써 서비스 간에 데이터 종속성을 낮추고, 한 서비스의 데이터 변경이 다른 서비스에 직접 영향을 주는 것을 피합니다.
- **소규모 팀에 의해 관리 가능**: 하나의 작은 팀(예: 2~10명)이 여러 개의 마이크로서비스를 관리할 수 있을 정도로 서비스가 경량입니다. 조직을 서비스별로 나누어 개발하면 팀 간 병목이 줄고 개발 속도가 향상될 수 있습니다.
- **교체 가능성**: 마이크로서비스는 **언제든 재작성하거나 교체할 수 있을 정도로 작은 단위**입니다. 처음 선택한 프레임워크나 언어가 나중에 적합하지 않으면 해당 서비스만 새로 작성하면 되므로, 기술 스택을 부분적으로 진화시킬 수 있습니다.

이러한 특성으로 인해 마이크로서비스 아키텍처에서는 서비스마다 **높은 자율성**과 **유연성**을 갖게 됩니다. 작은 서비스들은 각자 빠르게 개발되고 배포될 수 있어, 새로운 기능을 출시하거나 변경 사항을 반영하는 주기가 단축됩니다. 또한, 특정 서비스의 기능이 변경되어도 그 서비스의 **계약(Contract)** 만 준수하면 다른 서비스에는 영향을 최소화할 수 있습니다. 서비스 간 통신은 명확한 API나 메시지 계약으로 이루어지므로, 전체 시스템이 **느슨하게 결합(loose coupling)** 된 구조를 가지게 됩니다.

## 모놀리식 vs. 마이크로서비스

**모놀리식(monolithic) 아키텍처**에서는 모든 기능이 하나의 거대한 어플리케이션에 통합되어 있습니다. 초기에는 모놀리식이 단순할 수 있지만, 시스템이 커짐에 따라 몇 가지 한계가 나타납니다. **모놀리식 시스템의 단점**으로 흔히 언급되는 것들은 다음과 같습니다:

- **높은 결합도**: 모놀리틱 코드베이스에서는 모듈 간 의존성이 촘촘하여, 한 부분을 수정하면 예상치 못한 곳에서 문제가 발생할 수 있습니다. 부분적인 변경이 전체 시스템 재배포로 이어져 개발/배포 속도가 느려집니다.
- **규모 확장의 어려움**: 애플리케이션 전체를 확장해야 하므로, 특정 기능만 트래픽이 몰려도 전체 애플리케이션을 복제해서 배포해야 합니다. 자원 효율성이 떨어지고, 대용량 트래픽에 유연하게 대응하기 어렵습니다.
- **배포 및 유지보수 부담**: 한 번에 배포해야 할 변경 규모가 크고, 배포 과정이 복잡해집니다. 잘못되면 전체 서비스를 중단시킬 위험이 있어 배포가 점점 두려워질 수 있습니다. 또한 팀 규모가 커지면 여러 개발자가 한 코드베이스에 얽혀 충돌이 잦아지고 협업이 어려워집니다.

반면 **마이크로서비스 아키텍처**는 이러한 문제를 해결하고자 등장했습니다. **Netflix, Amazon** 등의 대규모 서비스를 운영하는 기업들이 모놀리스를 마이크로서비스로 전환하여 얻은 성공 사례가 잘 알려져 있습니다. 마이크로서비스의 주요 이점으로는 다음을 들 수 있습니다:

- **배포 독립성 및 민첩성**: 각 서비스가 작고 독립적이므로 새로운 기능이나 변경을 **지속적으로 배포**하기 좋습니다. 큰 애플리케이션에서는 출시 전 장기간의 통합 테스트가 필요하지만, 마이크로서비스는 변경 범위가 작아 **짧은 주기의 배포**가 가능합니다. 이는 결국 비즈니스의 빠른 피드백 수용과 실험에 유리하게 작용합니다.
- **스케일 아웃 용이**: 병목이 되는 특정 서비스만 **선별적으로 확장**할 수 있습니다. 예를 들어 주문 처리 서비스에 부하가 집중되면 그 서비스 인스턴스만 늘리면 되고, 다른 서비스는 그대로 둘 수 있습니다. 이러한 **유연한 확장성**은 **고가용성**을 확보하는 데도 도움이 됩니다.
- **기술 이질성 허용**: 전체 시스템을 통일된 기술 스택으로 구축해야 하는 모놀리스와 달리, 마이크로서비스 각각은 적합한 **프로그래밍 언어**나 **기술 스택**을 자유롭게 선택할 수 있습니다. 한 서비스는 C#으로, 다른 서비스는 Python으로 개발해도 무방하며, 각 서비스가 API로 소통하기만 하면 됩니다. 이를 통해 팀은 문제에 최적화된 도구를 사용할 수 있는 **기술적 유연성**을 얻습니다.

물론, 마이크로서비스가 만능 해법은 아닙니다. 작은 서비스로 나누면서 생기는 **추가 복잡성**이 존재하며, 이것이 **단점을 고려**해야 하는 부분입니다. 다음 섹션에서 마이크로서비스의 이러한 **도전 과제**들을 살펴보겠습니다.

## 마이크로서비스의 단점과 도전

마이크로서비스 아키텍처를 도입하면 얻는 이점이 많지만, 동시에 **극복해야 할 복잡성**과 비용도 만만치 않습니다. 주요 도전 과제는 다음과 같습니다:

- **분산 시스템의 복잡성**: 마이크로서비스 시스템은 곧 **분산 시스템**입니다. 네트워크를 통해 통신하므로, 함수 호출만으로 이루어지는 모듈간 상호작용보다 **신뢰성이 낮고 지연이 발생**합니다 . 서비스 간 통신 실패, 네트워크 지연, 데이터 일관성 문제 등 분산 컴퓨팅의 어려움이 고스란히 나타납니다. 또한 시스템 전체 동작을 한눈에 이해하거나 디버그하기 어려워집니다.
- **운영 및 모니터링 부담**: 서비스 개수가 많아지면 배포, 설정 관리, 모니터링 등 **운영(Ops)** 작업의 부담이 크게 늘어납니다. 수십 개 이상의 서비스가 각각 로그를 남기고 메트릭을 내보내므로, 이를 종합하여 **관찰가능성(Observability)** 을 확보하는 것이 필수입니다. 모니터링 시스템, 분산 트레이싱, 중앙화된 로그 관리 등 추가 인프라가 필요합니다.
- **서비스 경계 식별의 어려움**: 무엇을 하나의 서비스로 만들지 결정하는 **경계 설계**는 어렵습니다. 비즈니스 도메인에 대한 충분한 이해가 필요하고, 초기에는 최적의 경계를 알아내기 힘들어 시행착오를 겪을 수 있습니다. 잘못 분리된 경계는 서비스 간 지나친 의존성이나 데이터 중복을 초래하여 오히려 변화에 둔감한 시스템이 될 수 있습니다. 일단 경계가 정해진 뒤 이를 변경하는 것도 상당한 비용과 시간이 듭니다.
- **전체 시스템 테스트 어려움**: 분산된 서비스들로 이루어진 시스템에서는 **통합 테스트**나 **엔드투엔드 테스트**가 복잡합니다. 모든 서비스를 올려서 시나리오 테스트를 해야 하는데, 환경 설정부터 데이터 준비까지 많은 노력이 필요하고 안정적인 테스트를 보장하기 어렵습니다. 각 서비스별로는 테스트가 잘 통과되어도, 서비스 사이의 **계약 불일치**나 통신 오류로 인한 문제는 따로 검증해야 합니다.
- **운영 성숙도 요구**: 마이크로서비스를 성공적으로 활용하려면 조직과 개발팀이 **DevOps 문화**와 높은 **운영 성숙도**를 갖추어야 합니다. 즉, 개발팀이 서비스 개발뿐 아니라 배포와 모니터링, 장애 대응까지 책임지는 문화가 필요합니다. 자동화된 CI/CD 파이프라인 구축, 인프라 관리 능력, 장애 발생시 빠른 대응 등 **전체 서비스 수명주기에 대한 책임**이 요구됩니다.

따라서 **시스템의 복잡도가 일정 수준 이상**이고, **조직이 이러한 도전들을 감당할 준비가 되었을 때** 마이크로서비스 도입을 고려하는 것이 좋습니다. 작은 규모의 단순한 애플리케이션에 마이크로서비스를 적용하면 오히려 과잉설계가 될 수 있습니다. **마이크로서비스를 도입할 시점**에 대한 판단은 중요하며, 시스템의 복잡성, 팀의 역량, 배포 빈도 등의 요소를 종합적으로 고려해야 합니다. 적절한 상황에서 활용한다면 마이크로서비스는 **확장성과 민첩성을 확보**하는 강력한 수단이 될 것입니다.

---

# 마이크로서비스 설계

## 마이크로서비스 설계 원칙

마이크로서비스 아키텍처를 성공적으로 구현하려면 몇 가지 **핵심 설계 원칙**을 따라야 합니다. 마이크로서비스는 단순한 기술 구조뿐 아니라 **개발 문화와 원칙**을 포함하는 개념입니다. 마이크로서비스를 설계할 때 지침이 되는 대표적인 원칙들은 다음과 같습니다:

- **자율성(Autonomy)**: 각 서비스는 **자율적**으로 동작할 수 있도록 설계해야 합니다. 자율성이란 서비스가 자체적으로 모든 필요한 기능(데이터 저장, 비즈니스 로직, 외부 통신 등)을 갖추고, 다른 서비스에 최소한으로 의존한다는 의미입니다. 자율적인 서비스는 **느슨하게 결합**되며, 한 서비스의 변경이나 장애가 전체 시스템으로 전파되지 않도록 격리해줍니다. 이를 위해 데이터베이스를 공유하지 않고, 명확한 인터페이스(contract)를 통해서만 상호작용하도록 합니다.
- **단일 책임과 높은 응집도**: 앞서 언급한 **SRP(단일 책임 원칙)** 를 서비스 수준에 적용합니다. 하나의 서비스는 **하나의 일**을 잘 수행하도록 작게 유지하고, 서비스 내부 구성요소들은 해당 기능 수행에 긴밀히 관련되어 **응집도**가 높아야 합니다. 이렇게 하면 서비스 코드를 이해하기 쉽고 변경 범위가 명확해져, 새로운 요구사항에 민첩하게 대응할 수 있습니다.
- **독립적 배포와 지속적 전달**: 서비스들은 서로 **독립적으로 빌드, 테스트, 배포**될 수 있어야 합니다. 이를 위해 각 서비스는 별도의 저장소(repo)와 빌드 파이프라인을 갖고, 자체적인 CI/CD를 구현합니다. 이러한 독립 배포 가능성은 마이크로서비스의 필수 조건이며, 서비스의 크기와 책임 범위를 판단하는 기준이기도 합니다. 배포가 독립적이라는 것은 곧 **서비스 계약의 안정성**을 의미하므로, 하위 호환이 유지되도록 API를 설계해야 합니다.
- **회복탄력성(Resilience)**: 분산 시스템에서는 부분 실패가 항상 발생할 수 있으므로, 서비스는 **장애에 견디는 설계**가 필요합니다. 하나의 서비스가 실패해도 전체 시스템이 무너지지 않도록 **격리와 복구 전략**을 설계합니다. 예를 들어 타 서비스 호출에 실패하면 자체적으로 재시도하거나 우회 방법을 사용하고 (후술할 **폴리** 라이브러리 같은 도구로 구현), 장애 상황을 상위로 전파하지 않는 **서킷 브레이커 패턴** 등을 적용할 수 있습니다. 또한 서비스 자체적으로 **헬스 체크(health check)** 엔드포인트를 제공하여 오케스트레이션 도구가 문제 서비스를 신속히 감지하고 교체하게 합니다.
- **투명성(Transparency)과 모니터링**: 각 서비스는 자신의 상태와 동작을 **투명**하게 드러내야 합니다. 분산 환경에서는 문제가 어디서 발생했는지 파악하기 어려우므로, **로그, 메트릭, 분산 트레이싱** 등을 통해 서비스를 관찰 가능하게 만드는 것이 설계의 일부입니다. 이를 통해 운영자는 서비스 간 흐름을 추적하고, 성능 병목이나 오류를 신속히 찾아낼 수 있습니다.
- **비즈니스 기능 정렬(Alignment)**: 서비스 경계를 정할 때는 기술 기능보다는 **비즈니스 기능이나 도메인**에 따라 정렬하는 것이 좋습니다. 마이크로서비스는 조직의 도메인 모델을 반영하여 설계되며, 각 서비스가 해당 **비즈니스 역량**을 대표하도록 하는 것이 이해도나 확장성 면에서 유리합니다. 이는 **도메인 주도 설계(DDD)** 의 **Bounded Context** 개념과도 일맥상통하며, 팀 구조와 아키텍처를 정렬시키는 **컨웨이의 법칙**을 활용하는 것입니다.

이러한 원칙들을 종합하면, 잘 설계된 마이크로서비스는 **작지만 강력한 단위**로서, **명확한 경계**를 가지고, **안정적으로 독립 동작**하며, **쉽게 교체/확장 가능한** 모습을 띱니다. 다음으로, 이러한 원칙을 실제로 적용하여 **서비스 경계를 식별**하고 **데이터와 계약**을 설계하는 방법을 살펴보겠습니다.

## 서비스 경계 식별

**서비스 경계(Service Boundary)** 를 올바르게 식별하는 것은 마이크로서비스 설계의 핵심 과제입니다. 어떤 기능들을 묶어서 하나의 서비스로 만들고, 서비스를 분리하는 기준을 정하는 일은 정답이 없는 영역이며, 도메인 지식과 경험이 필요합니다. 다음은 서비스 경계를 모델링할 때 흔히 사용하는 몇 가지 접근 방식입니다:

- **비즈니스 기능(업무 능력) 기준**: 시스템이 제공하는 **비즈니스 기능별**로 서비스를 구성합니다. 예를 들어 전자상거래 도메인이라면 **주문 서비스**, **카탈로그 서비스**, **결제 서비스**, **배송 서비스** 등으로 나눌 수 있습니다. 이 접근 방식은 **도메인 주도 설계(DDD)** 의 **하위 도메인(Subdomain)** 이나 **bounded context**와 밀접하게 연관되며, 서비스 경계가 비즈니스 맥락과 일치하므로 변화에 강하고 팀 책임과도 자연스럽게 연결됩니다. 많은 마이크로서비스 프로젝트에서 권장되는 방법입니다.
- **사용 사례(Use Case) 기준**: 시스템의 주요 **사용 시나리오**나 **유스케이스**를 중심으로 서비스를 나눕니다. 예를 들어 "장바구니에 상품 추가"라는 유스케이스를 지원하기 위한 서비스들을 한 경계로 묶는 식입니다. 이 접근은 초기 모놀리스를 나누는 과정에서 특정 기능 개발을 빠르게 마이크로서비스화해야 할 때 고려될 수 있습니다. 다만, 유스케이스는 종종 여러 도메인을 아우르므로 장기적으로는 서비스 간 경계가 불분명해질 수 있어 신중해야 합니다.
- **기술/인프라 계층 기준**: 기술적인 **기능(Technical Capability)** 에 따라 분리하는 방법입니다. 예를 들어 **인증/권한 서비스**, **메일 전송 서비스**, **파일 저장 서비스** 등 공통 기술 서비스를 따로 분리하는 것입니다. 이는 **재사용 가능한 공통 서비스**를 만들 때 유용하지만, 지나치게 기술 관점으로만 나누면 비즈니스 흐름이 여러 서비스를 거치면서 복잡도가 증가할 수 있습니다. 일반적으로는 핵심 도메인보다는 보조적인 기능에 한정하여 적용합니다.
- **변경 및 확장 패턴(Volatility) 기준**: **변경의 빈도나 시급성**이 비슷한 것끼리 묶는 접근입니다. 자주 변경되는 기능과 거의 변경되지 않는 기능을 분리하여, 자주 바뀌는 서비스는 다른 서비스에 영향을 주지 않고 빠르게 진화시키는 것입니다. 또는 성능/확장성 요구가 특별한 부분을 독립 서비스로 빼서 별도 스케일링/튜닝을 가능하게 할 수도 있습니다. 예컨대 실시간 스트리밍 처리가 필요한 부분을 분리 서비스로 만드는 식입니다.

이러한 기준들을 **종합적으로 고려**하여 경계를 설정하는 것이 중요합니다. 초기에는 비즈니스 도메인에 따라 큰 덩어리로 나누고, 점진적으로 재구성하는 방법도 흔히 쓰입니다. 실제 현업에서는 모놀리식 시스템을 점진적으로 마이크로서비스로 **분해(Expand-Migrate-Contract 패턴)**하는 전략이 이용됩니다: 기존 모놀리스에서 일부 기능을 떼어내 새로운 서비스로 구현하고, 구 서비스와 병행 운용하면서 데이터를 이행(Migration)한 뒤, 검증되면 옛 기능을 제거(Contract)하는 식입니다. 이렇게 하면 위험을 줄이면서 **경계에 대한 학습과 개선**을 병행할 수 있습니다.

서비스 경계를 정의할 때 꼭 기억해야 할 점은 **서비스 간 결합을 최소화**해야 한다는 것입니다. **잘 정의된 경계**는 서비스들이 서로 **응집도 높게 내부 기능을 가지면서, 외부와는 작은 표면(API)으로만 소통**하게 해줍니다. 반대로 경계가 모호하면 한 기능 변경에 여러 서비스가 얽혀 수정되어야 하거나, 데이터가 여기저기 흩어져 일관성 문제가 생깁니다. 초기 설계 시 완벽할 수 없으므로, **모니터링과 팀 피드백을 통해 지속적으로 경계를 재평가**하고 필요하면 리팩터링(서비스 분할/병합)을 할 수 있는 자세도 필요합니다. 마이크로서비스의 작은 크기 덕분에, 설계가 잘못된 서비스는 **교체하거나 다른 서비스와 통합하는 것이 비교적 수월**하다는 것도 기억해둘 만 합니다.

## 데이터 관리와 일관성

마이크로서비스에서는 각 서비스가 **자신만의 데이터베이스**를 가질 것을 권장합니다. **데이터베이스 공유를 피하고** 서비스 경계와 데이터 경계를 일치시키면, 서비스 간 간섭 없이 데이터 스키마를 진화시키고 성능 최적화를 할 수 있습니다. 하지만 이러한 **데이터 분리**는 곧 **분산 데이터 일관성**의 문제를 가져옵니다. 즉, 한 서비스에서 발생한 데이터 변경사항을 다른 서비스와 **어떻게 동기화**할 것인가의 문제가 대두됩니다.

전통적인 모놀리식 환경에서는 하나의 관계형 DB 트랜잭션으로 여러 모듈의 데이터 변경을 **ACID**하게 처리할 수 있었지만, 마이크로서비스에서는 각 서비스가 별도 DB를 가지므로 **분산 트랜잭션**을 지양하게 됩니다. 분산 트랜잭션(two-phase commit 등)은 복잡도와 지연을 높이고 시스템을 취약하게 만들 수 있어, 일반적으로 마이크로서비스 아키텍처에서는 **궁극적 일관성(Eventual Consistency)** 개념을 채택합니다.

**궁극적 일관성**이란 모든 서비스의 데이터가 **즉시 실시간으로 동기화되지는 않더라도**, 일정 시간이 지나 일관된 상태에 수렴함을 보장하는 모델입니다. 이를 구현하는 대표적인 방법으로 **사가(Saga) 패턴**과 **이벤트 소싱(Event Sourcing)** 등이 있습니다:

- **사가 패턴(Saga)**: 분산된 서비스에 걸친 **비즈니스 트랜잭션**을 **여러 개의 지역 트랜잭션**으로 나누어 관리하는 패턴입니다. 각 서비스는 자신이 맡은 작업(지역 트랜잭션)을 수행하고, 다음 작업을 이벤트나 메시지로 다른 서비스에 전달합니다. 모든 단계가 성공하면 전체 트랜잭션이 완료되고, 중간에 실패가 발생하면 이전에 완료된 작업들을 보상 트랜잭션(undo 처럼)으로 롤백하여 최종 일관성을 맞춥니다. 예를 들어 주문 서비스에서 주문을 접수하고 결제 서비스에 결제 승인 요청 이벤트를 발행하면, 결제 서비스는 결제 처리 후 배송 서비스에 배송 요청 이벤트를 보내는 식으로 각 단계가 이벤트에 반응하여 처리합니다. 만약 결제 승인이 실패하면 주문 서비스에 **결제실패** 이벤트를 보내 주문을 취소하거나 보상 조치를 취할 수 있습니다.
- **이벤트 드리븐(Event-Driven) 데이터 일치**: 서비스들은 중요한 데이터 변경이 발생할 때 **이벤트를 발행(publish)**하고, 관련된 다른 서비스가 그 이벤트를 **구독(subscribe)**하여 자신의 데이터를 갱신하는 방식입니다. 예를 들어 **상품 서비스**가 상품 가격을 변경하는 이벤트를 발행하면, **카탈로그 서비스**나 **장바구니 서비스** 등이 그 이벤트를 받아 자신의 저장된 가격 정보를 업데이트합니다. 이런 구조에서 서비스들은 서로 직접 묻고 답하지 않아도 느슨하게 데이터 일관성을 유지할 수 있습니다. Nancy 프레임워크 예제에서도 장바구니 서비스가 `ItemAddedToShoppingCart` 이벤트를 발행하고, 추천 서비스나 재고 서비스 등이 이를 비동기로 처리하는 그림을 보여줍니다. 이벤트 기반 협업에서는 일시적으로 데이터 불일치가 있을 수 있지만, 시스템이 안정 상태에 이르면 데이터가 결국 일치하게 됩니다.

- **CQRS 및 조회 모델 분리**: **CQRS(Command Query Responsibility Segregation)**는 쓰기와 읽기 모델을 분리하여, **데이터 복제**를 통해 일관성을 유지하는 기법입니다. 하나의 서비스가 다른 서비스의 데이터를 즉시 참조해야 하는 경우, 다른 서비스의 데이터를 일부 **복제**하여 가지고 있을 수 있습니다. 예를 들어 주문 서비스가 사용자 프로필 정보를 필요로 한다면, 사용자 서비스로부터 필요한 정보만 이벤트를 통해 복제해 둘 수 있습니다. 이렇게 하면 주문 서비스가 **자신의 읽기 DB**만으로 필요한 정보를 얻고, 사용자 서비스가 일시적으로 다운되어도 주문 서비스는 영향을 받지 않습니다. 물론 복제된 데이터는 원본 변경 시 업데이트 이벤트를 받아 eventually sync 하는 방식으로 관리합니다.

데이터 일관성 문제를 해결하는 공통된 원리는 **동기적 결합을 피하고 비동기적 이벤트 흐름**을 활용하는 것입니다. 즉, 한 서비스가 다른 서비스의 DB를 직접 호출해서 즉각적인 응답을 받으려 하지 않고, 가능하면 이벤트나 비동기 메시지로 상호작용하여 **약결합**을 유지합니다. 이러한 아키텍처에서는 **데이터 중복**이 어느 정도 발생할 수 있지만, 이는 **일관성과 가용성을 맞바꾸는 설계 trade-off**로 받아들입니다. **“하나의 진실된 데이터 원본(single source of truth)”** 원칙이 마이크로서비스에서는 다소 완화되어, 여러 서비스에 데이터 사본이 존재할 수 있게 되는 것입니다. 다만, 데이터 사본의 수정을 직접 허용하지 않고 오직 해당 데이터의 오너(owner) 서비스만 변경을 허용하며, 이벤트를 통해 사본들을 갱신하는 규칙을 지킴으로써 데이터 정합성을 유지합니다.

요약하면, 마이크로서비스 환경에서는 **강한 일관성(strong consistency)** 대신 **궁극적 일관성(eventual consistency)**과 **분산된 트랜잭션 보상 전략**으로 데이터 일관성을 관리합니다. 이를 구현하기 위해 **명시적인 이벤트, 사가, CQRS 등의 패턴**을 활용하고, 서비스 간 **데이터 공유를 지양**하는 설계를 택합니다. 이러한 접근은 초기에는 복잡해 보일 수 있으나, 서비스 규모가 커질수록 데이터 종속성에서 오는 장애 전파를 막고 독립적인 확장과 배포를 가능하게 해주는 장점이 있습니다.

## 서비스 API와 계약(Contract)

마이크로서비스 간 통신은 **명확한 인터페이스**를 통해 이루어지므로, 각 서비스는 자신이 노출하는 **API 계약(Contract)**을 신중하게 설계해야 합니다. 여기서 계약이란 서비스가 제공하는 **요청/응답 형식, 메시지 포맷, 엔드포인트 URI, 데이터 스키마 등**을 모두 포함하는 개념입니다. 잘 정의된 서비스 계약은 다음과 같은 특징을 갖습니다:

- **간결성(Succinct)**: 계약은 꼭 필요한 요소만 포함하여 이해하기 쉽게 만듭니다. 불필요하게 복잡한 엔드포인트나 메시지 형식은 지양하고, 한 가지 기능당 하나의 명확한 API를 제공하도록 합니다.
- **완전성(Complete)**: 서비스를 사용하기 위해 필요한 사항을 모두 계약에 명시합니다. 예를 들어 요청에 필요한 헤더나 인증 방식, 반환되는 오류 코드 등의 정보를 문서화하여, 서비스를 소비하는 측에서 **예측 가능**하도록 합니다.
- **안정성(Backward Compatibility)**: 마이크로서비스는 독립 배포되므로, 서비스 A의 계약이 변경되더라도 그 서비스를 사용하는 서비스 B가 망가지지 않아야 합니다. 이를 위해 **버전 관리** 전략이 필수입니다. 일반적으로 **Semantic Versioning(语义版本)** 규칙에 따라, 하위 호환성이 유지되는 변경은 같은 메이저 버전 내에서 수행하고(예: v1.2 -> v1.3), 호환성이 깨지는 변경은 메이저 버전을 올려 별도의 경로(예: v2.0)를 통해 배포합니다. Kevin Hoffman는 “다수의 서비스가 독립적으로 배포되는 환경에서는 **엄격한 API 버전 관리와 호환성 유지** 전략이 필수”라고 강조합니다.
- **검증 및 모니터링 가능**: 계약을 중심으로 서비스 간 상호작용을 **테스트**하고 **모니터링**해야 합니다. 예를 들어 **소비자 주도 계약 테스트(Consumer-Driven Contract Test)**를 통해 소비자 서비스의 요구를 제공자 서비스의 계약과 대조 검증하거나, API 게이트웨이 레벨에서 호환성 체크를 자동화할 수 있습니다. 또한 계약에 정의된 대로 메시지가 오고가는지 **모니터링/로깅**하여 이탈 상황을 감지합니다.

서비스 계약은 **서비스들 간의 약속**과 같습니다. 서비스 소비자는 계약만 믿고 호출하며, 제공자는 그 계약을 준수할 것을 약속합니다. 만약 계약을 바꾸어야 한다면 (예를 들어 요청 파라미터를 추가해야 한다면), 이상적인 방법은 **Expand-Contract 패턴**을 따르는 것입니다: 먼저 새로운 계약 요소를 추가하고(확장), 일정 기간 구 계약과 신 계약을 모두 지원한 뒤, 충분히 소비자들이 전환했을 때 구 계약을 제거하는 방식입니다. 이렇게 하면 시스템 가용성을 해치지 않고 점진적으로 API를 진화시킬 수 있습니다.

또한 계약 설계 시 **API 우선 설계(API First)** 원칙을 따르는 것이 좋습니다. 즉, 서비스를 구현하기 전에 먼저 **외부에 노출될 API 형태**를 명세하고, 이에 대한 팀 합의나 소비자 피드백을 받은 후 구현에 들어갑니다. 이는 내부 구현보다 계약의 안정성과 명확성을 우선시하여, 개발 후반에 API를 뒤집는 재작업을 줄여줍니다. API 설계 도구나 명세(Swagger/OpenAPI 등)를 활용하면 이 과정을 수월하게 진행할 수 있습니다.

정리하면, 마이크로서비스 설계에서는 **"계약 우선"**이라는 마인드셋이 중요합니다. 각 서비스는 **작은 제품**처럼 자신의 API를 관리해야 하며, 타 서비스와의 관계를 계약 단위로 엄격히 다룹니다. 이를 통해 서비스 간 상호작용에서 발생하는 문제를 줄이고, 독립적인 배포와 개발을 원활하게 유지할 수 있습니다.

## 마이크로서비스 아키텍처 패턴

마이크로서비스를 설계하는 과정에서 사용되는 **공통 아키텍처 패턴**들이 몇 가지 있습니다. 이러한 패턴들은 특정 상황에서 어떻게 서비스들을 구성하고 상호작용시킬지에 대한 모범사례를 제공합니다.

- **API 게이트웨이 패턴**: 다수의 마이크로서비스로 구성된 시스템에서는 클라이언트가 개별 서비스에 일일이 요청하기 어렵습니다. 이때 **API 게이트웨이**를 두어 클라이언트의 모든 요청을 게이트웨이가 받고, 내부적으로 적절한 서비스로 **라우팅**하거나 응답을 **집계(Aggregation)**하여 돌려줍니다. API 게이트웨이는 인증/인가, 로깅, 캐싱 등 **교차 관심사**를 중앙에서 처리하고, **백엔드 서비스의 구현 세부사항을 클라이언트로부터 숨기는** 역할도 합니다. 예를 들어 모바일 앱이 `/user/dashboard`를 요청하면 API 게이트웨이가 사용자 정보 서비스, 주문 서비스, 알림 서비스 등에 각각 요청을 보내 응답을 모아 하나로 합쳐 반환할 수 있습니다. 이 패턴은 **엔드포인트 단순화**와 **네트워크 효율** 측면에서 유용하지만, 게이트웨이 자체가 시스템의 복잡성을 증가시키고 장애 시 단일 실패점(single point of failure)이 될 수 있어 이중화와 경량 구현이 필요합니다.
- **Aggregator(집계) 패턴**: API 게이트웨이와 유사하게, 한 서비스가 여러 서비스의 데이터를 모아 **복합 응답**을 생성하는 패턴입니다. 예를 들어 **리포트 서비스**가 내부적으로 여러 마이크로서비스(매출 서비스, 고객 서비스 등)에서 데이터를 가져와 하나의 리포트를 완성합니다. Aggregator 패턴은 **읽기(query)** 시나리오에서 유용하며, 클라이언트 복잡도를 줄이는 역할을 합니다. 단, 여러 서비스 호출에 걸친 **에러 처리**나 **부분 실패 대응** 로직을 잘 설계해야 합니다.
- **프록시/브로커 패턴**: 서비스간 **비동기 메시징**을 사용할 때 브로커(메시지 큐 시스템)를 통해 상호작용하는 패턴입니다. 서비스들은 직접 서로를 호출하지 않고, **메시지 브로커**에 이벤트나 명령을 게시하면, 브로커가 이를 구독한 서비스들에게 전달합니다. 이 패턴은 서비스들의 시간적 결합을 느슨하게 하고, 재시도나 부하조절 등 브로커의 이점을 활용할 수 있습니다. RabbitMQ, Kafka, NATS 등의 브로커가 여기에 활용됩니다. 이 패턴하에서 서비스는 브로커를 통해 통신하므로 서로의 존재를 몰라도 되며, **확장성**과 **격리**에 유리합니다. 다만 모니터링이 어려워질 수 있어 추적 메커니즘을 함께 도입해야 합니다.
- **사가 패턴(위에서 언급)**: 분산 트랜잭션을 관리하기 위한 패턴으로, **오케스트레이션 사가**와 **코레오그래피 사가**의 두 가지 스타일이 있습니다. 
  - *오케스트레이션 사가*: 중앙 조율자(Orchestrator) 서비스가 전체 프로세스의 흐름을 관리하며 각 단계 서비스를 호출합니다. 조율자는 미리 정의된 순서대로 서비스들을 호출하고, 실패 시 보상 작업을 트리거합니다. 장점은 흐름이 한 곳에 명시되어 관리가 쉬우나, 중앙 조율자가 복잡해지고 단일 장애점이 될 수 있습니다.
  - *코레오그래피 사가*: 각 서비스가 **이벤트를 통해 느슨하게 협력**합니다. 중앙 조율자 없이, 처음 트랜잭션 시작 서비스가 이벤트를 발행하면 다음 서비스들이 그 이벤트를 듣고 자신의 작업을 수행한 뒤 또 다른 이벤트를 내보내는 식으로 **춤을 추듯(choreography)** 상호작용합니다. 이 방식은 서비스 간 결합이 최소화되지만, 전체 프로세스 흐름을 파악하기 어려워질 수 있습니다.

- **Database per Service 패턴**: 엄밀히는 패턴이라기보다는 원칙에 가깝지만, 각 서비스마다 **독립적인 DB**를 사용하는 것을 지칭합니다. 만약 복잡한 조회 요구로 인해 데이터베이스 통합이 필요하다면, **CQRS**나 **View Database**와 같은 보조 패턴을 사용해 해결합니다. 예를 들어 데이터 웨어하우스나 BI툴 연계 목적으로 각 서비스 DB로부터 데이터를 주기적으로 추출해 별도 통합 DB에 모아놓고 조회 전용으로 쓰는 방식도 있습니다. 그러나 운영 트랜잭션은 어디까지나 각 서비스의 DB에서 일어나도록 하여 서비스 간 간섭을 막는 것이 핵심입니다.

이밖에도 **마이크로서비스 플랫폼 패턴**, **Sidecar 패턴**, **서비스 메시(Service Mesh)** 등 배포/운영 단계에서의 패턴들도 존재하지만, 이는 아키텍처보다는 인프라 측면에 가까우므로 여기서는 생략합니다. 중요한 점은, 이러한 패턴들을 상황에 맞게 조합하여 사용함으로써 **마이크로서비스의 복잡성을 관리**할 수 있다는 것입니다. 예를 들어 대규모 시스템에서는 API 게이트웨이 + 브로커 조합으로 외부 통신과 내부 통신을 분리하고, Saga 패턴으로 데이터 일관성을 유지하는 식으로 여러 패턴을 동시에 적용합니다.

설계 단계에서는 **문제**를 명확히 하고, 위 패턴들 중 적절한 것으로 **해결책**을 구성하는 사고가 필요합니다. 마이크로서비스 아키텍처는 일정 수준 이상의 복잡성을 수반하기 때문에, 검증된 패턴을 활용하여 설계상의 위험을 줄이고자 하는 것입니다. 각 패턴은 일종의 설계 **Trade-off**를 가지므로, 장단점을 이해하고 적용해야 합니다. 예를 들어, **이벤트 중심** 설계는 확장성과 느슨한 결합에 유리하지만, **일관성 지연**과 **디버깅 어려움**이 따르고, **동기 REST 호출**은 이해하기 쉽지만 **런타임 결합**과 **에러 전파**의 문제가 있습니다. 설계자는 이러한 트레이드오프를 저울질하여 시스템의 일부에는 동기 통신, 일부에는 비동기 이벤트를 쓰는 등 혼합 전략을 택하기도 합니다.

결론적으로, 마이크로서비스 설계에서는 **원칙**에 기반하여 **서비스 경계**를 설정하고, **데이터 분산**에 대비한 패턴을 적용하며, **API 계약**을 안정적으로 관리하는 것이 중요합니다. 그리고 이러한 요소들을 지원하는 다양한 패턴들을 적재적소에 활용함으로써, **복잡성은 낮추고 유연성은 높이는 아키텍처**를 달성할 수 있습니다.

---

# 마이크로서비스 통신

마이크로서비스 환경에서 **서비스 간 통신**은 설계 및 구현의 중심 과제입니다. 분산된 서비스들은 서로 협력하여 하나의 시스템을 이루는데, 이 상호작용을 어떻게 구현하느냐에 따라 시스템의 성능, 안정성, 복잡도가 크게 좌우됩니다. 마이크로서비스 통신에는 크게 **동기식 통신(synchronous communication)**과 **비동기식 통신(asynchronous communication)** 두 가지 방식이 있으며, 각각 장단점을 지닙니다. 또한 통신 과정에서 발생할 수 있는 오류나 지연에 대응하기 위한 **안정성 패턴**들도 중요합니다. 이번 장에서는 이러한 통신 방식과 기법들을 살펴보겠습니다.

## 동기식 통신 (REST API 등)

**동기식 통신**은 **요청-응답** 패턴으로 이루어지는 통신 방식입니다. 한 서비스가 다른 서비스에 요청을 보내면, 응답을 받을 때까지 기다리는 형태입니다. 가장 일반적인 예가 **HTTP 기반의 REST API 호출**입니다. Service A가 Service B의 REST 엔드포인트(URL)에 HTTP 요청을 보내고, Service B는 처리를 마친 후 결과를 응답으로 반환합니다. 이런 호출은 **RPC(Remote Procedure Call)**처럼 즉각적인 결과를 얻을 수 있어 사용이 간편하며, 순차적인 비즈니스 로직 구현에 적합합니다.

동기식 통신의 대표격인 RESTful API의 특징과 이점은 다음과 같습니다:

- **간단하고 범용적인 프로토콜**: REST는 HTTP를 기반으로 하므로, 별도의 통신 프레임워크 없이도 웹 요청으로 서비스를 호출할 수 있습니다. JSON이나 XML을 통해 데이터 교환이 가능하며, 브라우저나 cURL 같은 도구로도 쉽게 상호작용을 테스트할 수 있습니다.
- **명시적 인터페이스**: 각 서비스가 제공하는 URI 및 HTTP 메서드(POST, GET 등), 그리고 데이터 스키마가 명확히 정의되므로, **계약 기반 통신**이 가능합니다. 이를 통해 서비스 간의 의존성을 관리하고 버전 업그레이드 시 호환성을 검증할 수 있습니다.
- **즉각적인 피드백**: 호출자는 호출 결과(성공/실패, 데이터)를 즉시 받기 때문에, 다음 동작을 결정하기 쉽습니다. 예를 들어 주문 서비스가 결제 서비스에 결제 승인을 동기 호출하면, 결제 성공/실패 여부를 받아 그에 따른 로직을 바로 수행할 수 있습니다.

하지만 동기식 통신에는 **단점과 주의점**도 있습니다:

- **서비스 간 강한 시간적 결합**: 한 서비스가 다른 서비스를 호출할 때, 상대 서비스가 **사용 가능해야 하고 일정 시간 내 응답**해야 합니다. 만약 B 서비스가 다운되었거나 응답이 지연되면 A 서비스도 같이 지연되거나 실패하게 되어 **장애 전파**가 일어날 수 있습니다. 따라서 동기 호출에는 **타임아웃** 설정과 **예외 처리**가 필수이며, 장애 격리를 위한 패턴(서킷 브레이커 등)이 필요합니다.
- **네트워크 오버헤드**: 내부 프로세스 호출보다 **네트워크 호출은 지연이 크고 비싸며** 불확실성이 있습니다. 빈번한 동기 호출은 성능 저하를 초래할 수 있고, 특히 다단계 호출 체계(서비스 A가 B를, B가 C를 차례로 호출 등)는 전체 지연 시간을 증가시킵니다. 그러므로 동기 호출 체인을 가능한 짧게 유지하고, 대량의 데이터를 주고받는 경우엔 적합한지 고민해야 합니다.
- **로드 관리의 어려움**: 한 서비스에 트래픽이 몰려 호출이 폭증하면, 연쇄적으로 호출받는 서비스들도 부하를 견뎌야 합니다. 예컨대 API 게이트웨이가 주문 서비스를 1000건 호출하면, 주문 서비스가 다시 결제 서비스를 1000건 호출하는 식으로 부하가 전파됩니다. 동기식 구조에서는 **백프레셔(역압)**나 **큐잉** 개념이 없으므로, 호출 측에서 적절히 호출 속도를 제어하거나, 수신 측에서 부하를 분산시키는 추가 솔루션(로드 밸런싱, 스레드 풀 조절 등)이 필요합니다.

그럼에도 불구하고, **실시간 상호작용**이 필요하거나 순차 처리가 자연스러운 많은 시나리오에서 동기식 REST 호출은 널리 사용됩니다. .NET 환경에서는 `HttpClient` 클래스 등을 사용하여 손쉽게 HTTP 요청을 보낼 수 있습니다. 아래는 .NET의 `HttpClient`를 통해 다른 서비스의 API를 호출하는 예시입니다:

```csharp
// 다른 마이크로서비스의 API를 호출하여 제품 목록을 가져오는 코드 예시
using(var httpClient = new HttpClient())
{
    httpClient.BaseAddress = new Uri("https://api.product-service.local/");  // 대상 서비스 베이스 URL
    HttpResponseMessage response = await httpClient.GetAsync("/products?ids=123,456");
    if (response.IsSuccessStatusCode)
    {
        string resultJson = await response.Content.ReadAsStringAsync();
        // resultJson을 파싱하여 사용
    }
    else
    {
        // 오류 처리 (재시도 또는 예외 처리 등)
    }
}
```

위 코드에서는 `product-service`라는 다른 서비스의 `/products` 엔드포인트를 호출하여 제품 정보를 가져옵니다. 이처럼 동기식 호출은 **순차적으로 코드 작성이 가능**하고 이해하기 쉬워서 마이크로서비스 간 통신의 기본 수단으로 자주 쓰입니다. 현대적인 구현에서는 REST 외에도 **gRPC**와 같은 경량 RPC 프레임워크를 사용하여 **HTTP/2 기반의 동기 통신**을 구현하기도 합니다. gRPC는 IDL을 통해 인터페이스를 정의하고 바이너리 프로토콜로 통신하여 성능과 타입 안전성을 높여주며, 특히 다중 언어 환경에서 선호됩니다.

요약하자면, 동기식 통신은 **단순성**과 **즉각성**을 장점으로 하지만, **결합도 상승**과 **장애 전파 위험**을 수반합니다. 이를 보완하기 위해 다음에 다룰 **비동기식 통신** 방식과 혼합하여 사용하는 것이 일반적입니다.

## 비동기식 통신 (메시징 및 이벤트)

**비동기식 통신**은 서비스들이 **메시지 큐, 이벤트 스트림** 등을 통해 **느슨하게 연결**되는 통신 방식입니다. 한 서비스가 다른 서비스에게 직접 요청을 보내는 대신, **중간 매개체**(예: 메시지 브로커)에 메시지를 전달하면, 수신측 서비스가 이를 비동기로 받아 처리합니다. 대표적인 구현으로 **이벤트 기반 아키텍처**와 **메시지 큐를 통한 비동기 처리**가 있습니다.

비동기식 통신의 주요 특징과 장점은 다음과 같습니다:

- **시간적 디커플링(Decoupling)**: 송신자와 수신자가 동시 가용 상태일 필요가 없습니다. 송신 서비스는 메시지를 브로커에 넣고 곧바로 다음 일을 진행하며, 수신 서비스는 자신의 속도에 맞춰 메시지를 처리합니다. 이를 통해 **백프레셔**를 자연스럽게 흡수하고, **피크 부하를 완화**할 수 있습니다. 예를 들어 주문 서비스가 주문 접수 이벤트를 발행하면, 이메일 서비스는 바로 이메일을 보내지 않고 큐에 쌓인 이벤트를 순차 처리할 수 있습니다.
- **높은 확장성과 가용성**: 비동기 메시징 시스템은 구독자 수를 늘리거나 파티션을 추가하여 쉽게 확장할 수 있습니다. 또한 한 서비스가 일시적으로 중단되더라도 메시지가 **큐에 안전하게 보존**되므로, 나중에 서비스가 재가동되어 처리 가능하며, **내성(reliability)**이 향상됩니다.
- **관심사의 분리**: 이벤트 발행 서비스는 구체적으로 누가 그 이벤트를 소비하는지 몰라도 됩니다. 단지 "사건 발생" 사실만 알리고, 후속 처리는 관심 있는 서비스들이 수행합니다. 이는 새로운 서비스가 이벤트 구독자로 추가되더라도 기존 서비스들을 수정할 필요가 없음을 의미하므로, **기능 확장**이 용이합니다. (예: 장바구니 서비스가 `ItemAdded` 이벤트를 발행하면, 추천 서비스, 재고 서비스 등 여러 서비스가 해당 이벤트를 구독하여 각자 필요한 동작을 할 수 있습니다.)

비동기 통신에서 흔히 사용되는 메시징 패턴은 **발행/구독(pub-sub)**과 **포인트 투 포인트(queue)**입니다:

- *발행/구독*: 이벤트 스트림의 형태로 다수의 소비자가 있을 때 사용됩니다. 한 서비스가 이벤트를 발행(publish)하면, 관련 이벤트를 **구독(subscribe)**한 모든 서비스에 복사되어 전달됩니다. Kafka, RabbitMQ(토픽 익스체인지) 등이 이 패턴을 지원합니다.
- *포인트 투 포인트*: 정확히 하나의 수신자가 처리해야 하는 작업 큐의 형태입니다. 메시지를 한 곳에 보내면(queue/send), 하나의 소비자 서비스 인스턴스가 이를 가져가 처리하며, 다른 인스턴스들은 동일 메시지를 처리하지 않습니다. RabbitMQ의 작업 큐, AWS SQS 등이 이에 해당합니다.

비동기 통신의 단점이나 고려사항도 있습니다:

- **최종 일관성**: 앞서 데이터 일관성 부분에서 논의했듯, 비동기 방식에서는 데이터가 실시간 동기화되지 않으므로 **일시적인 불일치**가 발생할 수 있습니다. 개발자는 이 사실을 염두에 두고 시스템을 설계해야 하며, UI/UX에서도 즉각적인 피드백 대신 "처리 중" 상태 표시 등을 활용해야 할 수 있습니다.
- **복잡한 오류 처리**: 동기 호출에서는 예외가 즉시 호출자에게 전달되지만, 비동기 환경에서는 **오류 전파와 보상 논리**를 명시적으로 설계해야 합니다. 예를 들어 A 서비스가 보낸 메시지를 B 서비스가 처리하다 오류나면, B는 해당 메시지를 재처리하거나 Dead-letter 큐로 보내고, 이를 모니터링하여 별도 조치를 취해야 합니다. 또한 Saga 보상 트랜잭션 구현 등도 비동기 이벤트 기반으로 복잡해질 수 있습니다.
- **메시지 중복 및 순서**: 네트워크나 브로커 특성상 **중복 메시지**가 발생할 수 있고(적어도 한 번 전달), **처리 순서**가 보장되지 않을 수 있습니다. 따라서 수신 측에서는 메시지 **아이디empotency**(한 메시지를 여러번 받아도 결과 동일)와 순서 제어 로직을 고려해야 합니다. Kafka 같은 시스템은 파티션 단위 순서를 보장하지만, 여러 파티션에 걸친 전역 순서는 보장되지 않는 등 세부사항을 이해하고 코딩해야 합니다.

비동기 통신은 주로 **이벤트 드리븐 마이크로서비스**나 **비동기 커맨드 처리**(예: 작업 예약) 용도로 사용됩니다. 예를 들어 **이메일 발송, 로그 처리, 데이터 동기화** 등의 부차적 작업들을 비동기로 처리해 메인 서비스 흐름을 방해하지 않도록 합니다. Nancy를 이용한 예제에서, 쇼핑카트에 아이템이 추가되면 `ItemAddedToShoppingCart` 이벤트를 발행하고, **추천 서비스**는 이를 비동기로 수신하여 추천 상품을 업데이트하며, **재고 서비스**는 재고를 감소시키는 등 **코레오그래피 방식**으로 동작시킬 수 있음을 보여주었습니다. 이렇게 이벤트에 반응하는 서비스들은 **실시간으로 빠르게 반응**하면서도, 호출자와 분리되어 개별적으로 확장/관리됩니다.

정리하면, 비동기식 통신은 **유연성**과 **확장성** 면에서 마이크로서비스 아키텍처의 강력한 도구입니다. 특히 대규모 시스템에서 **느슨한 결합과 고가용성**을 달성하는데 필수적입니다. 다만 구현 복잡도가 증가하므로, 시스템 요구사항에 따라 동기와 비동기 방식을 **혼합**해 사용하는 것이 일반적입니다. 핵심 트랜잭션 경로나 간단한 조회는 동기 REST로 하고, 부하가 크거나 느슨한 연계가 가능한 부분은 이벤트 기반으로 처리하는 식입니다. 이런 **하이브리드 접근**을 통해 마이크로서비스들은 성능과 안정성의 균형을 맞출 수 있습니다.

## 통신상의 안정성과 패턴

분산 환경에서 통신은 언제든 실패할 수 있기 때문에, **안정성(resilience)**을 높이기 위한 여러 패턴과 도구들이 활용됩니다. 마이크로서비스 간 네트워크 호출에서 발생할 수 있는 일반적인 문제는 **타임아웃, 예외, 지연, 장애** 등이며, 이를 다루지 않으면 시스템 전반의 신뢰성이 떨어집니다. 아래에 이러한 문제에 대응하기 위한 대표적인 패턴들을 정리합니다:

- **타임아웃 설정**: 기본적이지만 가장 중요한 설정입니다. 동기 호출을 할 때는 항상 적절한 **타임아웃(timeout)**을 지정하여, 상대 서비스가 지연되거나 응답이 없을 때 무한 대기에 빠지지 않도록 해야 합니다. 타임아웃 값은 해당 서비스의 성능 특성 및 요구되는 응답 속도에 맞춰 정하고, 타임아웃 발생 시 취할 조치(재시도 또는 예외 처리)를 코드에 포함시켜야 합니다.
- **재시도 전략(Retry)**: 일시적인 네트워크 오류나 서비스 부하로 인한 실패에 대비해 **자동 재시도** 메커니즘을 두면 안정성이 향상됩니다. 이때 **즉각 재시도**가 아닌 **지수 백오프(Exponential Backoff)**나 **고정 지연 시간**을 두고 재시도하여, 연속된 실패 시에도 대상 서비스에 부담을 주지 않도록 합니다. .NET에서는 **Polly** 라이브러리를 사용하여 재시도 정책을 쉽게 구현할 수 있습니다. Polly는 다양한 재시도 및 폴백(fallback) 정책을 fluent API로 제공하며, 예를 들어 3회까지 재시도하되 점증하는 지연(1초, 2초, 4초)으로 대기하도록 설정할 수 있습니다.
- **서킷 브레이커(Circuit Breaker)**: 연속된 실패가 발생할 경우, 일정 기간 해당 서비스로의 호출을 아예 중단하여 **자체 보호**를 하는 패턴입니다. 이것을 전기 회로 차단기에 비유해서 서킷 브레이커라 합니다. 구현상으로 일정 횟수 이상 실패하면 회로를 **차단(open)**하여 바로 에러를 리턴하고, 내부적으로 일정 시간 후 반쯤 열려(half-open) 시범 호출을 해보고 성공하면 회로를 **닫는(close)** 식으로 동작합니다. 이 패턴은 장애가 발생한 서비스에 쏟아지는 과부하를 막아주고, 실패한 호출에 대한 **빠른 실패(fail-fast)**를 가능케 하여 요청 대기 큐를 비우는 효과도 있습니다 . Polly 라이브러리 역시 간단한 설정으로 서킷 브레이커를 구현할 수 있습니다.
- **벌크헤드(Bulkhead) 패턴**: 마이크로서비스 호출 측에서 사용하는 자원(스레드, DB 커넥션 등)을 격리된 풀(pool)로 분리하여, 하나의 외부 서비스 호출 지연이 전체 자원을 소진하지 않도록 하는 방법입니다. 예를 들어 외부 API A를 호출하는 쓰레드풀과 API B를 호출하는 쓰레드풀을 분리하면, API A가 지연되어 A풀의 쓰레드가 모두 대기 중이어도 B 호출용 쓰레드는 여전히 사용 가능하여 다른 기능은 정상 동작할 수 있습니다.
- **히스테릭스(Hystrix) 등의 프레임워크**: 과거 넷플릭스의 Hystrix 라이브러리가 재시도, 서킷 브레이커, 벌크헤드 등을 한데 제공하여 많이 사용되었지만, 이제는 Polly처럼 언어별 경량 라이브러리들이 그 역할을 대체하고 있습니다. 중요한 것은 **항상 네트워크 호출에 대한 실패 대비 코드를 넣는 습관**입니다.

또한 **서비스 디스커버리(Service Discovery)**와 **로드 밸런싱**도 통신 안정성의 한 축입니다. 서비스 인스턴스들은 동적으로 생겨났다 사라질 수 있기 때문에, 호출하는 쪽에서 대상 서비스의 위치(IP와 포트)를 알아내는 과정이 필요합니다. 이를 위해 **서비스 레지스트리**(예: Consul, etcd, Eureka)에 각 서비스 인스턴스 정보를 등록해두고, 호출 시 클라이언트 또는 중간 프록시(API Gateway나 Service Mesh)가 레지스트리에서 정보를 조회해 호출하는 방식을 씁니다. .NET Core의 `HttpClientFactory` 및 `IHttpClientBuilder`는 Polly와 통합되어 **재시도+서킷브레이커 정책과 서비스 디스커버리**를 결합한 스마트 HTTP 클라이언트를 구성할 수 있게 돕습니다.

Nancy 기반 예제 코드에서도 **Polly 활용**이 등장하는데, 예를 들어 **쇼핑카트 서비스**에서 상품 정보를 얻기 위해 상품 카탈로그 서비스에 HTTP 요청을 할 때 Polly의 재시도 정책을 적용하는 장면이 있습니다. Polly 설정은 대략 아래와 같이 이루어질 수 있습니다:

```csharp
// Polly를 이용한 재시도 정책 설정 (예: 최대 3번, 2^n 초 대기 간격)
var retryPolicy = Policy
    .Handle<HttpRequestException>()                // 처리할 예외 유형
    .WaitAndRetryAsync(3, retryAttempt => 
        TimeSpan.FromSeconds(Math.Pow(2, retryAttempt))
    );

// 사용 예시: 정책으로 감싸서 HTTP 호출 수행
HttpResponseMessage response = await retryPolicy.ExecuteAsync(() =>
    httpClient.GetAsync("/api/products/123"));
```

위 코드에서 `retryPolicy.ExecuteAsync`로 HTTP 호출을 감쌌기 때문에, 요청이 실패(Exception throw 또는 응답상태 오류 등 정의한 조건)하면 최대 3번까지 재시도를 하게 됩니다. 이처럼 **안정성 패턴들**은 비교적 적은 코드 수정만으로도 큰 효과를 볼 수 있으므로, 마이크로서비스 간 통신 구현 시 기본적으로 적용하는 것이 권장됩니다.

마지막으로, **일관된 통신 라이브러리/프레임워크 사용**도 고려해야 합니다. 각 팀이 제각기 다른 방식으로 HTTP 호출이나 메시징을 구현하면, 패턴 적용이나 버그 수정이 누락될 수 있습니다. 따라서 조직 차원에서 표준화된 **통신 SDK**나 **유틸리티**를 마련해 두고 (예: 공통 HttpClient wrapper, 공통 메시지 발행 유틸 등), 모든 서비스에서 활용하도록 하면 베스트 프랙틱스를 강제하고 유지보수를 용이하게 할 수 있습니다.

통신 안정성을 높이는 것은 궁극적으로 **사용자 경험의 안정성**으로 이어집니다. 마이크로서비스 아키텍처에서는 개별 요소 실패가 전체 실패로 번지지 않도록 하는 것이 목표이므로, 위에서 설명한 다양한 패턴들을 종합적으로 적용해 **탄력적인(resilient) 시스템**을 구현해야 합니다. 실제 운영 환경에서는 장애 상황을 가정한 **카오스 테스팅(chaos testing)**을 통해 이러한 대비책들이 잘 작동하는지도 검증하는 것이 좋습니다.

## API 게이트웨이와 서비스 디스커버리

앞서 **마이크로서비스 아키텍처 패턴**에서 API 게이트웨이와 서비스 디스커버리에 대해 간략히 언급했지만, 통신 측면에서 다시 정리해보겠습니다.

- **API 게이트웨이**: API 게이트웨이는 **클라이언트와 내부 마이크로서비스들 간의 통신을 중재**하는 프록시 계층입니다. 클라이언트는 게이트웨이에게만 요청을 보내고, 게이트웨이가 내부에서 어떤 서비스 조합이 필요한지 판단하여 대리로 호출한 뒤 응답을 합쳐 반환합니다. 예를 들어, 게이트웨이는 `/mobile/home` 요청을 받으면 내부적으로 사용자, 주문, 추천 등 여러 서비스를 호출해 결과를 취합한 후 사용자에게 돌려줄 수 있습니다. **장점**: 클라이언트는 단 한 곳과 통신하면 되므로 구현이 단순해지고, 인증/인가, 로깅, 모니터링을 한 곳에서 처리할 수 있습니다. **단점**: 게이트웨이가 병목이나 단일 실패점이 될 수 있으며, 게이트웨이 로직이 복잡해지면 또 다른 모놀리스가 될 위험이 있습니다. 따라서 게이트웨이는 가급적 단순한 라우팅과 공통 기능에 집중하고 비즈니스 로직은 최소화해야 합니다.
- **서비스 디스커버리**: 이것은 **동적 서비스 룩업**을 위한 메커니즘입니다. 마이크로서비스 환경에서는 컨테이너 오토스케일링 등으로 인스턴스가 늘고 줄거나 IP가 바뀌기 때문에, 고정된 호스트:포트로 서비스를 호출하기 어려울 수 있습니다. **서비스 레지스트리**(예: Consul, Eureka)에 각 서비스 인스턴스가 자신의 주소와 상태를 등록하고 주기적으로 갱신(heartbeat)하면, 다른 서비스나 게이트웨이가 레지스트리에서 대상 서비스의 목록을 조회하여 호출에 활용합니다. **클라이언트 사이드 디스커버리**에서는 호출자 서비스가 직접 레지스트리에서 인스턴스 정보를 가져와(예: `ServiceB`의 인스턴스 3개 중 하나 선택) 호출하며, **서버 사이드 디스커버리**는 API 게이트웨이나 서비스 메쉬 등이 대신 조회해서 라우팅해줍니다. 예를 들어 Kubernetes에서는 기본적으로 DNS를 통한 서비스 디스커버리를 제공하여, `http://orderservice` 같이 호출하면 자동으로 현재 가용한 OrderService 파드(pod)들 중 하나로 라우팅됩니다.

서비스 디스커버리는 투명하게 동작하기 때문에, 개발 코드에서는 보통 의식하지 않아도 프레임워크/플랫폼 레벨에서 처리됩니다. 다만, 컨테이너 오케스트레이션을 쓰지 않는 환경이라면 Netflix OSS의 Eureka + Ribbon(클라이언트 부하분산) 조합이나 Consul + sidecar 프록시 등을 도입하여 유사한 기능을 구현할 수 있습니다. .NET에서는 **Steeltoe** 라이브러리를 이용하면 Eureka, Consul 연동을 쉽게 할 수 있고, Polly와 통합하여 디스커버리된 인스턴스로 재시도 호출도 지원합니다.

API 게이트웨이와 서비스 디스커버리는 모두 마이크로서비스 통신에서 **상황에 따른 유연성**을 높여주는 요소입니다. 게이트웨이를 통해 버전 라우팅(A/B 테스트나 Canary 배포 지원)이나 요청 흐름 관리(API 조합) 등이 가능해지고, 디스커버리를 통해 장애 조치와 부하 분산이 자연스럽게 이뤄집니다. 이러한 인프라적인 지원이 뒷받침되어야 비로소 마이크로서비스들의 통신이 원활하고 안정적으로 유지될 수 있습니다.

---

# 마이크로서비스 테스트

마이크로서비스 아키텍처에서 **테스트**는 필수적인 요소입니다. 서비스가 작고 독립적으로 나누어지면서 전체 시스템의 구성이 복잡해졌기 때문에, 신뢰성을 확보하기 위해서는 다양한 수준의 테스트와 자동화가 뒷받침되어야 합니다. 또한 마이크로서비스는 **지속적 배포**를 지향하므로, 잦은 배포에도 기능이 망가지지 않도록 하는 **안전망**으로서 테스트가 중요합니다.

이 절에서는 마이크로서비스에서의 테스트 전략, 테스트 유형, 자동화 및 모범 사례에 대해 알아보겠습니다.

## 테스트의 중요성 및 원칙

마이크로서비스 환경에서 테스트의 중요성은 몇 가지 관점에서 강조됩니다:

- **안전한 변경의 전제**: 마이크로서비스는 작은 단위로 자주 배포되는데, **어떻게 변경이 안전한지 보장할 것인가**가 핵심입니다. 결국 자동화된 테스트가 뒷받침되지 않으면 서비스 분리가 오히려 개발 속도를 저해할 수 있습니다. 각 서비스가 독립적으로 배포 가능한 것은 사실상 **해당 서비스에 대한 신뢰**(confidence)가 있을 때만 의미가 있는데, 이 신뢰의 상당 부분이 테스트로부터 옵니다. 잘 갖춰진 테스트 수트가 있다면, 작은 수정 후 빠르게 검증하고 배포할 수 있어 **Continuous Delivery**의 기반이 됩니다.
- **교체 가능성 보장**: 이상적인 마이크로서비스는 **언제든 새로운 구현으로 교체**할 수 있어야 합니다. 예를 들어 현재 Java로 작성된 서비스를 .NET으로 새로 구현하더라도 기능만 동일하다면 교체 가능해야 하는 것이 이상입니다. 이때 두 구현이 동등한지 확인하는 것이 테스트의 역할입니다. 기존 서비스와 신규 구현을 동일한 테스트 수트로 검증해 모두 통과한다면, 기능적 동등성을 보장받고 교체를 자신 있게 진행할 수 있습니다.
- **작은 팀의 생산성**: 마이크로서비스는 작은 팀이 각각 여러 서비스를 책임지도록 설계됩니다. 한 팀이 관리하는 서비스들에 대한 테스트가 부족하면, 시간이 지날수록 서비스 동작을 확신하기 어려워 개발이 느려집니다. 반면 서비스별로 테스트가 충분하면, 팀은 코드를 리팩터링하거나 라이브러리를 업그레이드할 때도 테스트 결과를 보고 빠르게 의사결정할 수 있습니다. 이는 **개발 효율성**과 **심리적 안정감**을 높여줍니다.

이러한 이유들로, 마이크로서비스에서는 **“테스트 우선”**, **“자동화 우선”** 문화가 중요합니다. 실제로 많은 조직이 서비스 개발 시 **테스트 주도 개발(TDD)**이나 적어도 기능 개발과 테스트 작성이 동시에 이뤄지는 프로세스를 따르고 있습니다. 

## 테스트 종류와 범위

마이크로서비스 환경에서의 테스트는 **범위(scope)**에 따라 여러 종류로 나눌 수 있습니다. Nancy 프레임워크를 다룬 문헌에서는 이를 **테스트 피라미드**로 설명하고 있는데, 아래에서 각 계층별 테스트를 알아보겠습니다:

1. **단위 테스트(Unit Test)** – *피라미드 최하단, 좁은 범위 테스트*:  
   개별 서비스의 내부 함수나 모듈을 검증하는 테스트입니다. 한 함수나 클래스가 주어진 입력에 대해 예상 출력/동작을 보이는지를 빠르게 확인합니다. **의존성은 모두 모의(Mock) 또는 스텁으로 대체**하여, 외부 시스템(DB나 다른 서비스 등)에 의존하지 않고 순수 로직만 테스트합니다. 단위 테스트는 수백~수천 개를 작성해도 빠르게(몇 초~수십 초 내) 실행될 수 있어야 하며, 개발 중 수시로 돌려볼 수 있는 수준의 경량성을 가져야 합니다. 마이크로서비스에서는 서비스별로 단위 테스트를 작성하며, 일반적으로 각 서비스 저장소에 해당 코드와 함께 관리됩니다. 이 테스트들이 통과하지 않으면 이후 단계로 진행하지 않도록 CI에서 걸러내는 식입니다.
2. **통합 테스트(Integration Test)** – *피라미드 중간, 서비스 수준 테스트*:  
   여기서 통합이란, **서비스 내부의 구성 요소들** 또는 **서비스와 실제 인프라(데이터베이스, 메시지 브로커 등)**의 통합을 의미합니다. 예를 들어, Repository 클래스가 실제 DB에 연결되어 데이터를 잘 넣고 가져오는지, 또는 Web API 컨트롤러가 실제 웹 서버 환경에서 기대대로 동작하는지 확인하는 테스트입니다. 마이크로서비스에서는 각 서비스별로 **해당 서비스의 경계를 넘어가지 않는 통합 테스트**를 작성합니다. 예를 들어 Order 서비스의 통합 테스트는 Order 서비스와 실제 DB, 또는 임베디드 DB 환경과의 연동을 포함할 수 있지만, Payment 서비스까지 호출하지는 않습니다. .NET Core에서는 **테스트용 WebHost**를 띄워 실제 HTTP 요청을 보내 보는 식으로 API를 테스트하기도 하고, Nancy의 경우 **Nancy.Testing 브라우저**를 사용해 인메모리에서 모듈을 구동하고 HTTP 요청을 시뮬레이션하는 방식을 제공합니다.
3. **서비스 간 통합 테스트(또는 계약 테스트)** – *중간/상단*:  
   이 단계는 개별 서비스가 아니라, **두 개 이상의 서비스가 실제 통신을 통해 잘 협동하는지**를 테스트합니다. 흔히 **소비자-프로바이더 계약 테스트(Consumer-Provider Contract Test)** 형태로 수행됩니다. 예를 들어 Service A(소비자)가 Service B(제공자)의 API를 호출한다고 하면, B가 문서화한 스펙대로 A가 호출하고 B가 응답하는지를 확인합니다. 이를 위해 B 서비스에 대한 **모의 서버(Mock Server)**를 띄워 A를 테스트하거나, 반대로 A를 모의 클라이언트로 두고 B를 테스트할 수 있습니다. 도구로는 **Pact** 같은 계약 테스트 프레임워크가 널리 알려져 있습니다. 이러한 테스트는 서비스 경계 사이의 호환성을 미리 검증하여, 런타임 오류를 예방합니다. 특히 마이크로서비스처럼 독립 배포되는 환경에서는, 계약 테스트를 통해 **사전 호환성 체크**를 하는 것이 중요합니다.
4. **엔드투엔드 테스트(E2E Test)** – *피라미드 최상단, 넓은 범위 테스트*:  
   시스템의 여러 서비스를 모두 포함한 시나리오 테스트입니다. 사용자의 관점에서 시스템에 상호작용했을 때, **비즈니스 플로우가 완결**되는지를 검사합니다. 예를 들어 "사용자가 상품을 주문하면, 재고가 줄고, 주문 내역이 조회되며, 확인 이메일이 발송된다"와 같은 시나리오를 실제 구동된 마이크로서비스들 환경에서 테스트합니다. 엔드투엔드 테스트는 **실제 배포 환경과 유사하게** 세팅된 통합 테스트 환경(스테이징 등)에서 수행하는 경우가 많습니다. 자동화된 UI 테스트(Selenium 등)나 API 시나리오 스크립트(Postman/Newman, Cucumber 등)를 활용할 수 있습니다. 이 테스트들은 범위가 넓고 실행 시간이 오래 걸리기 때문에, 적은 수만 선별하여 유지하고 중요한 시나리오 위주로 커버합니다.

일반적으로 **테스트 피라미드** 원칙에 따라, **단위 테스트는 많고 빨라야 하며**, 위로 갈수록 **개수는 줄고 무거워야** 합니다. Nancy 책에서도 "넓은 범위의 테스트(시스템 테스트)는 적게, 좁은 범위의 테스트(유닛 테스트)는 많이" 가지라는 조언을 하고 있습니다. 이는 테스트 효율성과 유지보수 측면에서 옳은 접근인데, 너무 많은 엔드투엔드 테스트는 느리고 깨지기 쉬워 CI 파이프라인을 느려지게 하고 개발 생산성을 해칠 수 있기 때문입니다. 따라서, 마이크로서비스 개발에서는 각 서비스 별로 **단위/통합 테스트**를 충분히 갖춘 후, 서비스 간 **계약 테스트**로 보완하고, 최종적으로 몇 가지 **E2E 테스트**로 마무리하는 전략이 많이 사용됩니다.

## 테스트 자동화와 CI 파이프라인

테스트의 효과를 극대화하려면 **자동화**가 필수입니다. 마이크로서비스 아키텍처에서는 서비스 수가 많아 수동으로 테스트를 일일이 돌리기 어렵고, 서비스마다 릴리즈 주기도 달라질 수 있기 때문에, CI/CD 파이프라인에서 테스트 자동화를 잘 구성해야 합니다.

- **CI(Build) 단계**: 서비스의 코드를 커밋하면 **지속적 통합(CI)** 서버가 해당 서비스의 **빌드와 테스트를 즉시 수행**합니다. 예를 들어 Git 푸시에 반응하여 Jenkins나 GitHub Actions가 도는 식입니다. 이때 **단위 테스트와 서비스 통합 테스트**는 빠르게 실행되어야 하므로 컨테이너 내부에서 모두 구동하거나, 필요한 임베디드 인메모리 DB 등을 활용해 진행합니다. 이러한 자동화로 개발자는 커밋이 서비스의 품질을 해치지 않았는지 수분 내에 피드백을 받을 수 있습니다.
- **스테이징 환경 통합 테스트**: 계약 테스트나 E2E 테스트는 보통 모든 관련 서비스가 배포된 통합 환경에서 실행합니다. 한 가지 방법은 일정 주기마다 (또는 특정 서비스 배포 후) **스테이징 환경에 전체 시스템을 배포**하고 나서 통합 시나리오를 테스트하는 것입니다. 또는 소비자-제공자 계약 테스트는 각각 독립적으로 수행되지만, 결과를 중앙 서버(Pact Broker 등)에 모아 **계약 합의가 깨지지 않았는지** 확인하는 체계를 둘 수도 있습니다.
- **테스트 및 품질 게이트**: 모놀리식일 때보다 마이크로서비스에서는 테스트 결과를 한눈에 보기가 어렵습니다. 서비스별로 분산되어 있기 때문입니다. 이를 해결하기 위해 CI 시스템이나 대시보드에서 **전체 서비스의 테스트 현황**을 집계하고, 중요한 시나리오에 대해선 통합된 리포트를 볼 수 있게 하는 것이 좋습니다. 예를 들어, 모든 서비스의 테스트 커버리지, 최근 빌드 상태 등을 모아서 보여주는 포털을 운영하거나, 챗봇을 통해 배포 전에 계약 테스트 결과를 요약해서 알려주는 등입니다.
- **테스트 데이터 관리**: 마이크로서비스 테스트에서는 각 서비스별로 **고립된 테스트 데이터**를 사용하는 것이 이상적입니다. 단위 테스트는 하드코딩된 값으로 충분하겠지만, 통합 테스트 이상부터는 DB나 외부 시스템에 접근하게 됩니다. 이를 위해 테스트용 DB를 매 빌드마다 초기화하거나 Docker로 서비스+DB를 함께 올려주는 방식을 씁니다. 또는 계약 테스트 시에는 생산 데이터와 유사한 예제 객체(JSON 등)를 미리 정해두고 상호 주고받게 하여, 데이터 불일치로 인한 문제를 발견하기도 합니다.

Nancy를 이용한 마이크로서비스 책에서는 **Nancy.Testing 라이브러리**를 사용해 **엔드포인트 테스트**를 자동화하는 예제를 보여줍니다. Nancy.Testing의 `Browser` 클래스를 이용하면 실제 웹 서버를 띄우지 않고도 Nancy 모듈에 HTTP 요청을 보내는 통합 테스트를 쉽게 작성할 수 있습니다. 예를 들어, CurrentDateTimeModule (현재 시간 반환 서비스)에 대한 테스트는 다음과 같이 작성할 수 있습니다:

```csharp
var browser = new Browser(with => with.Module<CurrentDateTimeModule>());

// 루트 URL에 GET 요청 보내기
var response = browser.Get("/");

// 상태 코드 및 응답 검증
Assert.Equal(HttpStatusCode.OK, response.StatusCode);
DateTime result = response.Body.DeserializeJson<DateTime>();
Assert.True(result <= DateTime.UtcNow && result > DateTime.UtcNow.AddMinutes(-1));
```

위 테스트는 Nancy의 `Browser`가 CurrentDateTimeModule을 로드하여, `/` 경로 GET 요청을 보낸 후 응답이 200 OK이고, 반환된 UTC 시간이 현재 시각과 근접한지 확인합니다. 이처럼 프레임워크의 테스트 지원 기능을 활용하면 서비스 레벨에서 HTTP API를 검증하는 **경량 통합 테스트**를 손쉽게 만들 수 있습니다. .NET Core의 경우 `Microsoft.AspNetCore.Mvc.Testing` 패키지를 사용해 비슷하게 WebApplicationFactory를 통해 가상 호스트를 띄워 API를 테스트할 수 있습니다.

**테스트 피라미드 준수**와 **자동화 파이프라인 구축**은 궁극적으로 **지속적 배포(Continuous Delivery)**의 핵심입니다. 마틴 파울러의 말처럼, 배포를 자동화하고 작게 자주할 수 있지만, 그것이 의미 있으려면 충분한 테스트로 **프로덕션 배포에 대한 신뢰**가 확보되어야 합니다. 작은 변화라도 잘못되면 즉시 탐지해내는 테스트 수트, 그리고 이를 빠르게 실행하는 자동화 환경이 받쳐줄 때 비로소 마이크로서비스 팀은 빠른 속도로 안정적인 소프트웨어를 출시할 수 있습니다.

## 테스트에 사용되는 도구 및 팁

- **테스트 프레임워크**: .NET 환경에서는 xUnit, NUnit, MSTest 등이 단위/통합 테스트에 널리 사용됩니다. Java는 JUnit, Python은 PyTest 등 언어별 표준 프레임워크를 활용하면 됩니다.
- **모의 객체(Mock)와 테스트 더블**: 단위 테스트 시 서비스의 외부 의존을 격리하기 위해 **모킹 프레임워크**를 사용하면 편리합니다. .NET에서는 Moq, Java에서는 Mockito 등이 인기입니다. 하지만 지나친 모의 객체 사용은 테스트가 구현 세부사항에 묶이게 할 수 있으므로, 가능한 한 간단한 **페이크 구현**으로 대체하거나 설계를 개선하는 것이 바람직합니다.
- **테스트 격리**: 서비스별로 테스트가 완전히 격리되어야 합니다. 한 서비스 테스트가 다른 서비스에 접근하거나, 공유 데이터베이스를 건드리는 일이 없도록 합니다. 이를 위해 Docker Compose 등을 이용해 테스트 환경을 구성하기도 합니다. 예를 들어, CI에서 Order 서비스 테스트를 할 때 Order DB 컨테이너와 필요한 브로커 컨테이너만 띄워 사용하고 종료하면, 다른 서비스와 충돌 없이 깨끗한 환경을 유지할 수 있습니다.
- **성능 테스트와 혼돈 테스트**: 기능 테스트 외에도, **부하 테스트**나 **카오스 엔지니어링**도 중요합니다. 특히 마이크로서비스에서는 대량의 서비스 인스턴스와 복잡한 호출 관계가 있으므로, jMeter나 Locust 등으로 서비스별 성능을 측정하고, Chaos Monkey 같은 도구로 무작위로 서비스 인스턴스를 죽여보면서 시스템의 회복력을 테스트하기도 합니다. 이는 운영 단계에서의 품질을 담보하는 데 도움이 됩니다.

Nancy 예제에 의하면, **“자동화된 테스트 없이는 마이크로서비스 개발은 관리 불가능하다”**고까지 표현하고 있습니다. 그만큼 테스트는 선택이 아닌 필수이며, 처음부터 테스트를 염두에 두고 아키텍처와 코드를 설계하는 것이 현명합니다. 예컨대, 서비스 모듈을 테스트하기 쉽게 **의존성 주입(DI)** 구조로 짜두면, 나중에 테스트 작성이 수월해집니다.

마지막으로, **테스트 문화**도 언급해야겠습니다. 마이크로서비스 팀은 개발자에게 **테스트 작성에 대한 책임**을 부여하고, 테스트를 깨뜨리는 변경을 하면 바로 피드백을 주는 문화를 가져야 합니다. 서비스간 계약을 수정할 때는 해당 계약 테스트를 업데이트하고, 다른 팀과 소통하여 조율하는 등의 협업이 필요합니다. 이처럼 **“테스트 된 코드만 배포”**한다는 원칙 하에 움직이는 조직만이 마이크로서비스의 복잡성을 이겨내고 지속적으로 품질을 유지할 수 있습니다.

---

# 마이크로서비스 배포

마이크로서비스 아키텍처의 효과를 제대로 누리기 위해서는 **배포(deployment)** 전략이 뒷받침되어야 합니다. 수십 개 이상의 서비스가 각각 빈번하게 배포된다면, 이를 효율적으로 관리하고 자동화하지 않으면 운영이 매우 어려워집니다. 따라서 마이크로서비스 도입 시 **CI/CD 파이프라인 구축**, **컨테이너 사용**, **오케스트레이션 도구 활용**, **배포 패턴 적용** 등이 필수 과제로 떠오릅니다.

이 절에서는 마이크로서비스 환경에서의 배포에 대해, **지속적 통합/배포**, **컨테이너와 쿠버네티스**, **배포 패턴**, **운영상의 모니터링** 관점에서 살펴보겠습니다.

## 지속적 통합과 지속적 배포 (CI/CD)

**Continuous Integration/Continuous Delivery(CI/CD)**는 마이크로서비스의 빠른 개발과 배포를 가능하게 하는 엔진과도 같습니다. 앞선 테스트 장에서도 언급되었듯, 서비스별로 기능을 추가하고 수정한 후 이를 빈번하게 배포하려면 사람의 개입 없이 **자동으로 빌드, 테스트, 배포**까지 이뤄지는 파이프라인이 요구됩니다.

- **Continuous Integration (CI)**: 개발자들이 코드를 자주 통합(보통 하루에도 여러 번 커밋)하고, 그때마다 자동으로 **빌드와 단위 테스트**를 수행하는 프로세스입니다. CI 서버(Jenkins, GitLab CI, GitHub Actions 등)가 소스 코드 저장소를 감시했다가 커밋이 발생하면 빌드를 돌리고, 테스트 성공 여부를 팀에 피드백합니다. 마이크로서비스에서는 서비스별로 CI 파이프라인을 구성하거나, 모놀리포지토리(monorepo)일 경우 경로별로 파이프라인을 나누기도 합니다. CI를 통해 **품질이 확보된 아티팩트(예: 패키지, 컨테이너 이미지)**가 생성되며, 이는 이후 단계인 CD로 넘어갈 준비를 마칩니다.
- **Continuous Delivery/Deployment (CD)**: **Continuous Delivery**는 CI 이후 프로세스, 즉 **스테이징 배포, 추가 테스트, 운영 배포 준비**까지 자동화하는 것을 의미합니다. 여기서 Delivery와 Deployment는 종종 혼용되지만, 일반적으로 Continuous Deployment는 개발팀이 코드 커밋 -> 프로덕션 반영까지 전 과정이 자동으로 이뤄지는 것을 뜻합니다. Continuous Delivery는 프로덕션 배포 직전까지 자동화하되, 실제 프로덕션 반영은 사람의 승인 등으로 제어할 수 있는 상태를 말합니다. 마이크로서비스에서는 충분한 테스트 자동화를 갖췄다면 **Continuous Deployment**까지 노려볼 수 있습니다. 즉, 코드 커밋 -> CI -> 자동 테스트 -> (승인) -> 프로덕션 배포가 몇십분 안에 일어나는 것입니다. 이렇게 하면 새로운 기능이나 변경 사항을 사용자에게 매우 빠르게 제공할 수 있어 **비즈니스 응답성**이 높아집니다.

CI/CD 파이프라인을 설계할 때 염두에 둘 점:

- **파이프라인 표준화**: 모든 서비스가 비슷한 단계의 파이프라인(빌드 -> 테스트 -> 이미지 생성 -> 배포)을 가지도록 템플릿을 만들고, 새 서비스 생성 시 쉽게 적용합니다. 이렇게 하면 여러 서비스의 배포 과정을 일관되게 관리할 수 있고, 운영 복잡성이 감소합니다.
- **검증 단계**: 앞서 테스트 부분과 연결되는데, 파이프라인의 각 단계에서 **품질 검증**을 수행합니다. 예를 들어, 빌드 단계에서 정적 분석(SonarQube 등)을 실행하고, 테스트 단계에서 모든 레벨의 자동화 테스트를 돌린 뒤, 배포 전 단계에서 연기된(e2e) 시나리오 테스트나 장애내성 테스트를 실행할 수 있습니다. 각 검증을 통과한 변경만 다음 단계로 넘어갑니다. 이러한 **다중 단계 품질 게이트**를 통해, 최종 배포될 빌드는 “거의 확실히 문제 없다”는 신뢰를 얻습니다.
- **아티팩트 관리**: 빌드 후 생성된 산출물(아티팩트)를 일관되게 관리해야 합니다. 일반적으로 **컨테이너 이미지**로 빌드하여 버전 태그를 달고, 조직의 프라이빗 Docker 레지스트리에 업로드해 둡니다. 또는 JVM이라면 JAR 패키지를 Nexus와 같은 artifact repo에 보관할 수도 있습니다. 중요한 건 어떤 커밋이 어떤 빌드/이미지에 대응되는지 추적 가능해야 하며, 이미지 자체는 **불변(Immutable)**으로 다뤄야 한다는 것입니다. “Immutable artifact”란 한 번 빌드된 바이너리는 변경되지 않고, 환경별 설정만 외부에서 주입하여 사용한다는 개념입니다. 이를 통해 "개발 환경에서 테스트한 바로 그 코드가 프로덕션에도 올라간다"는 신뢰를 줄 수 있습니다.

Kevin Hoffman의 .NET 마이크로서비스 예제에서는 **Wercker**라는 CI 서비스를 사용해 Docker 이미지 빌드 및 푸시, 그리고 이후 클라우드에 배포하는 흐름을 보여줍니다. Wercker YAML 설정에 따라 Git 푸시 시 Docker 이미지를 만들고, 도커허브에 업로드하며, (옵션에 따라) 쿠버네티스 등에 배포까지 수행합니다. Morgan Bruce의 책에서도 Jenkins Pipeline을 활용하여 서비스 코드를 빌드 -> Docker 이미지화 -> 테스트 -> 프로덕션까지 자동화하는 과정을 다룹니다. 이처럼 도구는 다양하지만, 핵심은 **“코드에서 프로덕션까지 원터치”**를 실현하는 것입니다. 그래야 수십 개 서비스가 제각기 릴리즈될 때도 인력 소모 없이 관리가 됩니다.

Continuous Delivery를 잘 수행하면, **리릴리즈 공포감이 줄어들고** 오히려 **배포가 일상적 사건**이 됩니다. 이는 모놀리틱 시대의 "몇 달에 한 번 대규모 릴리즈"와 대비되는 마이크로서비스 시대의 문화적 변화이기도 합니다. 최종적으로, 지속적 배포 파이프라인이 마련되면 개발팀은 코드 변경에만 집중하고, 배포는 파이프라인에 안착시키기만 하면 자동으로 배포되는 **개발 생산성의 극대화**를 경험하게 됩니다.

## 컨테이너와 쿠버네티스

마이크로서비스 배포에서 **컨테이너(Container)** 기술은 사실상 표준이 되었습니다. Docker로 대중화된 컨테이너는 애플리케이션과 그 실행환경을 가볍게 패키징하여 어디서나 동일하게 실행할 수 있게 해줍니다. 이는 마이크로서비스의 **다양한 기술 스택**과 **빈번한 배포** 요구에 딱 맞는 기술입니다.

컨테이너 도입의 이점:

- **이식성(Portability)**: 개발자가 로컬에서 Docker로 서비스 컨테이너를 빌드하고 테스트한 뒤, 그 이미지를 프로덕션 서버나 클라우드에 배포하면 동일하게 동작합니다. OS 환경 차이나 라이브러리 버전 차이로 인한 “환경 문제”를 크게 줄여줍니다.
- **격리(Isolation)**: 각 서비스는 컨테이너 안에서 격리되어 실행되므로, 서로 다른 서비스 간 라이브러리 충돌이나 포트 충돌 등이 없습니다. 또한 CPU, 메모리 제한 등을 설정하여 한 서비스 컨테이너가 폭주해도 다른 서비스에 영향을 덜 주도록 격리할 수 있습니다.
- **신속한 확장과 복구**: 컨테이너는 기동이 빨라 (수 초~수십 초 내) 서비스 인스턴스를 추가 생성하거나 장애난 인스턴스를 재기동하기 쉽습니다. 이미지 하나만 있으면 새로운 인스턴스를 얼마든지 찍어낼 수 있으므로, **스케일 아웃/인 자동화**에 유리합니다.

이러한 이유로 대부분의 마이크로서비스 프로젝트는 각 서비스별 Dockerfile을 작성하고, CI에서 Docker 이미지를 생성하여 레지스트리에 push한 다음, **컨테이너 오케스트레이션** 도구를 통해 배포/운영합니다.

**쿠버네티스(Kubernetes)**는 오늘날 가장 널리 쓰이는 컨테이너 오케스트레이션 플랫폼입니다. Kubernetes를 사용하면 다음을 자동화하고 관리할 수 있습니다:

- **서비스 스케일링 및 로드밸런싱**: 각 서비스(Deployment 단위)의 원하는 인스턴스 수를 선언하면(Kubernetes manifest), 쿠버네티스가 해당 수로 맞춰줍니다. 필요 시 Horizontal Pod Autoscaler 등을 통해 부하에 따른 인스턴스 증감도 자동화 가능합니다. 또한 쿠버네티스는 각 서비스에 클러스터 내부 IP(DNS 이름)를 부여하고, Service 리소스를 통해 로드밸런싱을 제공하므로, 서비스 디스커버리와 부하 분산이 내장됩니다.
- **셀프 힐링(Self-healing)**: 컨테이너가 죽으면 쿠버네티스가 자동으로 재시작하며(RestartPolicy), 지정된 헬스 체크에 실패하는 인스턴스를 감지하여 트래픽에서 제외하고 다시 살리는 등 **자동 복구** 기능이 있습니다. 이는 마이크로서비스 환경의 운영 부담을 크게 줄여주며, 운영 인력이 일일이 개입하지 않아도 **항상 원하는 상태**를 유지하게 해줍니다.
- **배포 전략 관리**: 쿠버네티스는 Rolling Update, Recreate 등의 **배포 전략**을 기본 제공합니다. Rolling update를 쓰면, 새로운 버전 컨테이너를 하나씩 띄우고 구 버전을 하나씩 내리는 식으로 무중단 배포를 수행합니다. 또한 Canary 배포나 Blue-Green 배포를 쿠버네티스에서 구현하기 위해 Argo Rollouts 같은 추가 툴을 쓰기도 합니다. 어쨌든, **배포 과정이 표준화**되어 선언적으로 관리되므로, 사람이 수작업할 여지가 줄고 실수가 예방됩니다.
- **환경 독립성**: 쿠버네티스 manifest 파일(deployment, service 등 YAML)은 개발/스테이징/운영 환경에서 거의 동일하게 사용되며, 다른 것은 이미지 태그나 replica 수 등 약간 뿐입니다. 그래서 인프라를 코드로 유지하며, **GitOps** 같은 방식으로 배포 상태를 소스저장소에서 관리하는 것도 가능합니다.

Morgan Bruce의 *Microservices in Action*에서도 Kubernetes를 사용하여 컨테이너화된 서비스를 관리하는 부분을 다루고 있습니다. Minikube (로컬 쿠버네티스)로 예제를 보여주며, 마이크로서비스를 쿠버네티스에 **패키징 및 배포**하는 과정을 시연합니다. 이는 현대적인 마이크로서비스 운영에서는 사실상 기본 스택이 되었고, .NET 생태계에서도 Azure Kubernetes Service(AKS)나 AWS EKS, 온프레미스 K8s 등을 활용하는 것이 흔합니다.

쿠버네티스 외에도 AWS ECS나 Nomad 등 다른 스케줄러가 있지만, 핵심 개념은 유사합니다: **컨테이너로 패키징하고, 오케스트레이터가 배포/확장/치유를 책임지게 한다**는 것입니다. 개발자는 서비스 코드와 컨테이너 정의에 집중하고, 복잡한 배포 작업은 최대한 자동화하는 방향입니다.

## 배포 패턴 (Canary, Blue-Green 등)

여러 서비스가 자주 배포되는 마이크로서비스 환경에서는 **배포로 인한 장애를 최소화**하기 위한 다양한 **배포 패턴**이 활용됩니다. 특히 새로운 버전을 배포할 때 기존 버전과 조화롭게 트래픽을 처리하거나, 신속한 롤백이 가능하도록 하는 전략들이 중요합니다.

- **Blue-Green Deployment**: 두 개의 환경(Blue=현재 프로덕션, Green=새 버전)을 운영하다가, Green 환경에 새 버전 서비스를 모두 띄워 준비되면 트래픽 스위치를 Blue에서 Green으로 한꺼번에 넘기는 방식입니다. DNS 스위치나 로드밸런서 설정 변경으로 구현합니다. 장점은 배포 전후 환경이 분리되어 있어 기존 환경에 전혀 영향 없이 검증 가능하고, 문제가 생기면 다시 Blue로 쉽게 되돌릴 수 있다는 것입니다. 단점은 두 세트의 인프라 자원이 일시적으로 필요해 비용이 들고, 데이터베이스 변경처럼 공통자원 변경시에는 동시에 적용되어야 하는 부분 관리가 필요합니다.
- **Canary Deployment**: 새 버전을 전체 사용자에게 노출하기 전에 **일부 트래픽에만 적용**해보는 방식입니다. 예를 들어 새 버전 서비스를 10% 정도만 릴리즈하여 전체 트래픽의 10%만 새 버전이 처리하게 하고, 나머지 90%는 구버전이 처리하도록 합니다. 일정 시간이 지나 안정적이면 점차 비율을 늘려 100%로 전환합니다. 이 과정에서 오류율, 성능지표 등을 모니터링해 이상이 있으면 즉시 새 버전 비율을 줄이거나 롤백하는 등 대응합니다. 쿠버네티스에서는 서비스의 replica 중 일부만 새 버전 이미지로 바꾸거나, Istio와 같은 서비스메시의 트래픽 분할 기능을 이용해 Canary를 구현할 수 있습니다. 이 패턴은 **실제 트래픽으로 검증**한다는 장점이 있지만, 애플리케이션이 무상태 또는 호환성을 유지해야 하는 등 조건이 필요하고, 관찰 및 자동화 체계가 잘 갖춰져야 효과적입니다.
- **Rolling Update**: 앞서 언급한 쿠버네티스 기본 전략으로, **점진적 교체**를 의미합니다. 한 인스턴스씩 새 버전으로 바꾸는 동안 나머지 인스턴스는 구버전으로 운영되어, 전체 서비스를 중단하지 않고 업그레이드합니다. 이는 Blue-Green의 변형으로 볼 수 있는데, Blue-Green이 환경 단위라면 Rolling은 인스턴스 단위로 파란->초록 교체를 하는 셈입니다. 잘 동작하지만, 배포 도중에는 새 버전과 구 버전이 동시에 트래픽을 처리하므로 **하위 호환성**이 확보되어야 합니다. 즉, 새/구 버전 간 API나 데이터 스키마 호환이 안 되면 Rolling 중 오류가 날 수 있습니다.
- **Shadow Deployment**: 그림자 배포라고 하며, 새 버전 서비스가 실제 트래픽을 처리하되 그 결과를 사용하지 않고 버려버리는 방식입니다. 예컨대 로드밸런서가 요청을 기존 서비스(A)와 새 서비스(B) 둘 다에게 보내고, A의 응답만 사용자에게 전달하는 식입니다. B의 응답은 모니터링 용도로만 사용합니다. 이를 통해 실트래픽으로 부하 테스트와 기능 검증을 동시에 하지만, 사용자 영향은 없도록 할 수 있습니다. 구현이 복잡하여 흔히 쓰이진 않지만, 고위험 변경에서 시도될 수 있습니다.

이런 패턴들은 주로 **DevOps 플랫폼이나 도구**의 지원을 받아 사용됩니다. 예를 들어 Spinnaker나 Argo CD 같은 배포 도구는 Blue-Green, Canary를 원클릭으로 설정해줍니다. AWS Elastic Beanstalk, Google Cloud Deploy 등도 기본적으로 Blue-Green 배포 옵션을 제공합니다.

마이크로서비스에서는 개별 서비스가 fail 하더라도 전체 장애로 이어지지 않을 수 있지만, 핵심 서비스(예: 인증 서비스)가 잘못 배포되면 광범위한 문제를 일으킬 수 있습니다. 따라서 이러한 안전한 배포 패턴을 적용해 **배포 리스크를 줄이는 것**이 매우 중요합니. 특히 CI/CD를 통해 배포 빈도가 높아지면, 장애가 발생할 확률도 누적되어 올라가기 때문에, 이를 상쇄하기 위한 방어 기법으로 배포 패턴이 활용되는 것입니다. 

Morgan Bruce는 "신뢰할 수 있는 배포는 지루할 정도로 평범해야 한다"라고 언급하며, 자동화되고 검증된 배포 파이프라인의 중요성을 강조합니다. 그리고 "Canary나 Blue-Green과 같은 패턴의 활용"을 통해 배포 위험을 관리할 것을 권장합니다. 즉, 배포 자체는 큰 이벤트가 아니라 일상적인 일이 되어야 하고, 문제가 생겨도 빠르게 감지 및 복구(롤백)할 수 있는 체계를 준비해두라는 것입니다.

## 모니터링과 운영 (Observability)

배포된 마이크로서비스를 **운영**하는 단계에서는 **모니터링, 로깅, 트레이싱** 등 **Observability(관찰 가능성)** 요소가 중요합니다. 이는 배포 그 자체라기보다 배포 이후의 이야기지만, 마이크로서비스 아키텍처의 완성을 위해 잠깐 언급합니다. 운영 환경에서 각 서비스의 **상태(Health)**, **성능(Metrics)**, **로그(Log)**, **분산 추적(Trace)** 정보를 수집하고 대시보드화하여, 배포된 서비스들이 제대로 동작하는지 지속적으로 살펴야 합니다. 특히 Canary 배포 중이라면, 신규 버전 인스턴스의 메트릭(에러율, 응답속도) 등을 집중 모니터링하여 구버전 대비 이상이 없는지 확인하게 됩니다.

마이크로서비스 운영 툴체인 예:

- **모니터링/메트릭**: Prometheus, Grafana 조합으로 각 서비스의 CPU, 메모리, 요청 수, 에러 수 등을 수집/시각화.
- **로깅**: ELK(Stack) 또는 EFK(ElasticSearch + Fluentd + Kibana)로 분산 로그 중앙집중 관리, 검색.
- **트레이싱**: Jaeger, Zipkin 등으로 서비스 간 분산 트랜잭션 추적, 지연 분석.

이러한 observability가 갖춰져야 **배포 전후로 서비스 상태 변화를 감지**하고, 문제가 생기면 즉각 원인을 찾아 대응할 수 있습니다. Morgan Bruce 책에서도 StatsD, Prometheus, Grafana, ELK, Jaeger 등을 활용해 **모니터링 시스템 구축**과 **로그/트레이스 수집** 챕터를 따로 할애하고 있습니다.

결국, **배포 = 시작**일 뿐입니다. 배포된 후 제대로 동작하는지 확인하고, 사용자에게 영향이 없는지 살피는 것까지를 포함해야 비로소 성공적인 배포라 할 수 있습니다. 마이크로서비스 환경에서는 이 모든 과정이 **지속적이고 자동화**되며, 팀은 **DevOps** 문화 속에서 개발과 운영을 함께 책임지게 됩니다. 

**요약**: 마이크로서비스 배포에서는 CI/CD 파이프라인, 컨테이너 및 쿠버네티스, 안전한 배포 패턴, 그리고 모니터링 체계를 결합하여 **신속하면서도 안정적인 배포**를 실현하는 것이 목표입니다. 이를 통해 서비스 변경 사항을 빠르게 사용자에게 전달하면서도 서비스 중단이나 품질 저하를 최소화할 수 있습니다. 운영 단계에서의 피드백이 곧바로 다시 개발로 이어지는 **루프를 빠르게 돌릴 수 있는 환경** - 이것이 마이크로서비스를 통한 **지속적인 가치 제공**의 핵심이라고 할 수 있습니다.

---

# 실습 코드

마이크로서비스 개념과 원리를 공부했다면, 간단한 **실습 코드**를 통해 이를 직접 확인해보는 것이 큰 도움이 됩니다. 이번 절에서는 앞서 다룬 내용과 관련된 작은 코드 예제들을 살펴보겠습니다. 예제는 C# 언어와 .NET 환경을 활용하며, **Nancy 프레임워크**(경량 .NET 웹 프레임워크)와 **Polly 라이브러리** 등을 사용합니다. 이를 통해 마이크로서비스의 구현 감각과 테스트 방법을 익힐 수 있습니다.

## 예제 1: 간단한 마이크로서비스 작성 (Nancy 사용)

첫 번째 예제로, **현재 시간**을 반환하는 아주 단순한 마이크로서비스를 만들어보겠습니다. Nancy 프레임워크를 사용하면 적은 코드로 HTTP 엔드포인트를 정의할 수 있습니다. 다음 코드는 Nancy 모듈을 정의하여, **루트 경로 (`"/"`)로 들어오는 GET 요청에 현재 UTC 시간을 응답**하도록 구현한 것입니다:

```csharp
using Nancy;
using System;

public class CurrentDateTimeModule : NancyModule
{
    public CurrentDateTimeModule()
    {
        // GET 요청에 대한 엔드포인트 정의: 경로 "/" 
        Get("/", _ => DateTime.UtcNow);
    }
}
```

위 코드에서 `NancyModule`을 상속한 `CurrentDateTimeModule` 클래스의 생성자에서 `Get("/")`로 경로와 처리를 등록합니다. `Get("/", _ => DateTime.UtcNow)`는 `"\"` 경로에 대한 GET 요청을 받으면 람다식(`_ => DateTime.UtcNow`)을 실행하여 그 결과를 반환한다는 뜻입니다. Nancy는 이 반환된 `DateTime` 객체를 JSON으로 직렬화하여 HTTP 응답 본문으로 보내줍니다.

이제 이 마이크로서비스를 실행하면, 브라우저 또는 HTTP 클라이언트로 `http://localhost:5000/`에 접근했을 때 현재 시간이 담긴 JSON 문자열이 응답됩니다. 예를 들어:

```
GET / HTTP/1.1
Host: localhost:5000
Accept: application/json
```

응답:
```
HTTP/1.1 200 OK
Content-Type: application/json; charset=utf-8

"2025-04-09T14:30:00.1234567Z"
```

이처럼 Nancy 프레임워크를 사용하면 몇 줄의 코드만으로도 하나의 **작동하는 마이크로서비스**를 만들 수 있습니다. 비록 실용적인 서비스는 아니지만, **마이크로서비스의 기본 구조** – 경량 웹 서버 + 하나의 기능 – 를 감 잡을 수 있는 간단한 예제입니다.

이 서비스를 더욱 발전시키려면 RESTful하게 경로를 추가하고, 예를 들어 `/hello/{name}` 경로로 이름을 받아 인사말을 반환한다든지, 데이터 저장소와 연동하여 CRUD API를 만들 수도 있습니다. 중요한 것은 **서비스를 작게 유지**하고, **각각을 독립적으로 실행 가능**하게 만드는 것입니다. 위 예제는 독립적인 웹 애플리케이션으로 포트 5000에서 실행되며, 다른 서비스와 분리되어 배포될 수 있다는 점에서 마이크로서비스의 형태를 갖춥니다.

## 예제 2: 서비스 간 통신과 폴리(Polly)를 이용한 재시도

두 번째 예제는 마이크로서비스 간에 **HTTP 통신**을 수행하는 코드와, **Polly 라이브러리로 안정성**을 강화하는 모습을 보여줍니다. 가정해보면, **쇼핑카트 서비스**가 **상품 정보 서비스**에 REST API 호출을 해서 상품 상세 정보를 얻어온다고 합시다. 그리고 이 호출은 일시적으로 실패할 수도 있으므로 재시도 로직을 넣어보겠습니다.

```csharp
using System;
using System.Net.Http;
using Polly;
using Polly.Retry;
using Newtonsoft.Json;

// Polly 재시도 정책: 최대 3번 재시도, 각 재시도 사이에 2^n 초 대기
AsyncRetryPolicy<HttpResponseMessage> retryPolicy = Policy<HttpResponseMessage>
    .Handle<HttpRequestException>()                        // HTTP 요청 예외 처리
    .OrResult(msg => !msg.IsSuccessStatusCode)             // 응답이 200대가 아니면 재시도
    .WaitAndRetryAsync(3, attempt => TimeSpan.FromSeconds(Math.Pow(2, attempt)));

// 상품 서비스에서 상품 상세 목록 가져오기 (ids: 상품 ID 배열)
async Task<Product[]> GetProductDetailsAsync(int[] ids)
{
    string idQuery = string.Join(",", ids);
    using(var httpClient = new HttpClient())
    {
        httpClient.BaseAddress = new Uri("http://product-service.local/");
        HttpResponseMessage response = await retryPolicy.ExecuteAsync(() =>
            httpClient.GetAsync($"/api/products?ids={idQuery}")
        );

        // Polly에 의해 여기 도달하면 성공 응답을 받은 것
        string json = await response.Content.ReadAsStringAsync();
        return JsonConvert.DeserializeObject<Product[]>(json);
    }
}
```

위 코드에서는 먼저 Polly의 `Policy`를 사용해 재시도 정책(`retryPolicy`)을 정의했습니다 . 이 정책은 `HttpRequestException` 예외가 발생하거나, HTTP 응답이 성공 코드(200~299)가 아닐 경우 재시도를 트리거합니다. 최대 3회까지 시도하며, 재시도 간격은 2^n 초(2, 4, 8초 ...)로 증가하도록 설정했습니다. 

그 다음 `GetProductDetailsAsync` 함수에서는 `HttpClient`를 이용해 상품 서비스의 API를 호출합니다. `retryPolicy.ExecuteAsync` 안에 실제 HTTP GET 호출을 람다로 넣어서 실행함으로써, 요청 실패 시 Polly가 자동으로 재시도를 해줍니다. 만약 3번 시도에도 성공하지 못하면 `ExecuteAsync`에서 예외를 던지겠지만, 그 전에 성공하면 응답을 받아 JSON을 파싱하여 `Product[]` 결과를 리턴합니다.

이 코드 조각을 통해 살펴볼 수 있는 점:

- **서비스 간 통신**: `httpClient.BaseAddress`를 `product-service`의 URL로 설정하고 GET 요청을 보내는 부분이 **동기식 REST 통신**입니다. 마이크로서비스에서는 이렇게 다른 서비스의 API를 호출하거나, 메시지 브로커에 이벤트를 발행하는 식으로 통신합니다. 본 예제는 HTTP GET이지만 POST/PUT 등으로 데이터를 보내거나 명령을 실행시킬 수도 있습니다. 
- **네트워크 오류 처리**: Polly를 이용함으로써 네트워크 호출의 오류나 비정상 상태코드에 대응했습니다. 만약 상품 서비스가 한동안 응답하지 않으면 2초 후 재시도, 그래도 실패하면 4초 후 재시도 식으로 시도합니다. 이 동안 쇼핑카트 서비스의 해당 요청 처리 흐름은 대기하지만, **폴리시를 통한 제어**로 무한대기나 즉시 실패를 피하고 **희망적인 재시도**를 합니다. 3번 실패 시에는 결국 예외로 간주하여 상위 로직에서 처리해야겠지만(예: 사용자에게 "상품 정보를 가져올 수 없습니다" 오류 표시), 재시도 함으로써 일시적 오류로부터 복구할 가능성을 높였습니다.
- **JSON 직렬화**: 서로 다른 서비스 간에는 보통 JSON이나 ProtoBuf 등의 **플랫폼 중립적인 포맷**으로 데이터를 주고받습니다. C#에서는 JSON을 객체로 변환하기 위해 위 예시처럼 `JsonConvert.DeserializeObject<T>`를 사용했습니다. 이때 `Product` 클래스는 상품 ID, 이름, 가격 등을 프로퍼티로 가진 간단한 POCO 클래스일 것입니다.

Polly를 이용한 이 예제는 Nancy 책의 쇼핑카트 예제와 유사한 맥락입니다. 실제로 해당 책에서는 Polly로 **Product Catalog 서비스** 호출시 **재시도와 서킷브레이커**를 적용하는 코드를 다루고 있습니다. .NET 마이크로서비스 개발 시 Polly는 사실상 표준으로 쓰일 만큼 중요하며, 간단한 설정으로 위와 같은 네트워크 호출 안정성을 높여주므로 반드시 익혀두는 것이 좋습니다.

## 예제 3: 마이크로서비스 테스트 (Nancy.Testing 사용)

세 번째 예제는 마이크로서비스의 **테스트 코드**를 작성하는 방법을 보여줍니다. 앞서 예제 1에서 만든 `CurrentDateTimeModule`에 대해 **통합 테스트**를 작성해보겠습니다. Nancy에는 `Nancy.Testing`이라는 패키지가 있어, 실제 웹 서버를 열지 않고도 Nancy 모듈을 메모리 상에서 실행해볼 수 있습니다.

```csharp
using Nancy;
using Nancy.Testing;
using Xunit;  // xUnit 테스트 프레임워크
using System;

public class CurrentDateTimeModuleTests
{
    [Fact]
    public async void GetRoot_ReturnsCurrentUtcTime()
    {
        // Nancy 테스트용 브라우저 생성, 테스트 대상 모듈 등록
        var browser = new Browser(with => with.Module<CurrentDateTimeModule>());

        // 현재 시각 기준으로 테스트 실행
        DateTime before = DateTime.UtcNow;
        var response = await browser.Get("/", ctx => {
            ctx.Header("Accept", "application/json");
        });
        DateTime after = DateTime.UtcNow;

        // 응답 상태 코드 검증
        Assert.Equal(HttpStatusCode.OK, response.StatusCode);

        // 응답 본문 JSON을 DateTime으로 역직렬화
        DateTime result = response.Body.DeserializeJson<DateTime>();

        // 결과 시간이 테스트 실행 시각 범위 내인지 확인
        Assert.InRange(result, before, after);
    }
}
```

위 테스트 코드는 xUnit 프레임워크를 사용하고 있으며, 하나의 테스트 (`GetRoot_ReturnsCurrentUtcTime`)를 정의했습니다. 이 테스트에서 주목할 부분:

- `Browser` 객체를 생성할 때 `with.Module<CurrentDateTimeModule>()`로 우리가 테스트하려는 Nancy 모듈을 등록했습니다. 이렇게 하면 `browser` 객체가 해당 모듈을 가진 상태로 HTTP 요청을 시뮬레이션합니다.
- `browser.Get("/")`를 호출하여 루트 경로에 GET 요청을 보냈습니다. `ctx.Header("Accept", "application/json")`는 JSON 형식으로 응답을 원한다는 헤더를 추가한 것입니다. 이제 `response` 객체에는 시뮬레이션된 HTTP 응답이 담깁니다.
- 응답 검증: 먼저 `StatusCode`가 200 OK인지 확인하고, `response.Body.DeserializeJson<DateTime>()`를 통해 본문 JSON 문자열을 `DateTime` 객체로 변환했습니다. 그리고 그 `result` 값이 테스트 시작 직후부터 응답 직전(`before`~`after`) 사이에 있는 값인지 `Assert.InRange`로 확인했습니다. 즉, 모듈이 반환한 시간이 현재 시간과 비교해 너무 과거도 미래도 아니어야 통과할 것입니다.

이 테스트는 빠르게 실행되며, 외부 의존성이 없이(HTTP 요청도 실제 네트워크 안 타고, Nancy가 내부에서 처리) 동작하므로 **통합 테스트**이지만 **단위 테스트에 가깝게 경량**입니다. Nancy를 안 쓴 ASP.NET Core Web API라면 `TestServer`나 `WebApplicationFactory`를 사용하여 비슷하게 작성할 수 있고, 또는 Controller를 직접 호출하는 단위 테스트를 짤 수도 있습니다.

마이크로서비스에서는 이렇게 **서비스 단위의 테스트**를 충분히 만들어두고, CI에서 항상 돌려서 실패가 없도록 유지해야 합니다. 위 테스트 예제는 아주 단순한 것이지만, 실제로는 서비스의 다양한 엔드포인트에 대해 여러 케이스(정상, 에러, 경계 조건 등)를 검사하는 테스트들이 필요합니다. 또한 서비스 간 계약 테스트도 별도로 작성되어야 하지만, 그것까지 이 예시에서 다루진 않았습니다.

마지막으로, 이 코드들을 프로젝트에 넣고 실행해보려면 Nancy와 Nancy.Testing, Newtonsoft.Json, Polly, xUnit 등의 NuGet 패키지를 설치해야 합니다. 2017년경 Nancy 프레임워크가 .NET Core에서 잘 동작했고 책의 예제도 이에 기반하지만, 현재(2025) .NET 6+ 환경에서는 **ASP.NET Core Minimal API**나 **Carter**(Nancy의 정신적 계승자) 같은 것을 쓰는 편입니다. 다만 Nancy의 예제는 개념 학습용으로 여전히 유효합니다.

---

위 실습 코드를 통해 우리는 **마이크로서비스의 구현 기본기**를 맛보았습니다:

- 예제 1: **경량 서비스** 하나를 만들고 실행하는 법.
- 예제 2: **서비스 간 통신**과 **안정성 패턴(재시도)** 적용.
- 예제 3: **서비스 테스트**를 작성하여 동작을 검증.

실제 현업에서는 이보다 훨씬 복잡한 상황(데이터베이스 연동, 메시징, 인증, 권한 등)을 다뤄야 하지만, 핵심은 이런 작은 조각들의 연장선에 있습니다. 여러 서비스를 각각 잘 만들고, 통신을 견고하게 하며, 자동화된 테스트와 배포로 품질을 담보하면, 그것이 곧 마이크로서비스 아키텍처의 성공으로 이어질 것입니다.

흥미가 있다면, 이 코드들을 직접 실행하고 확장해 보십시오. 예컨대 Polly에 **서킷 브레이커** 정책을 추가해본다든지, Nancy 모듈을 하나 더 만들어 다른 모듈을 호출하게 구성해본다든지, Docker로 컨테이너를 만들어보는 등 연습을 통해 개념을 공고히 할 수 있습니다. **코드 실습을 병행한 학습**은 개념 이해를 더욱 쉽게 만들어 줄 것입니다.